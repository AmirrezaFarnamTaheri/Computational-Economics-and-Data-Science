{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# === Environment Setup ===\n",
    "import os, sys, math, time, random, json, textwrap, warnings\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from scipy.optimize import fsolve\n",
    "from IPython.display import display, Markdown, Image\n",
    "\n",
    "# --- Configuration ---\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams.update({'font.size': 14, 'figure.figsize': (12, 8), 'figure.dpi': 150,\n",
    "                     'axes.titlesize': 'large', 'axes.labelsize': 'medium',\n",
    "                     'xtick.labelsize': 'small', 'ytick.labelsize': 'small'})\n",
    "np.set_printoptions(suppress=True, linewidth=140, precision=4)\n",
    "\n",
    "# --- Utility Functions ---\n",
    "def note(msg, **kwargs):\n",
    "    display(Markdown(f\"<div class='alert alert-info'>\ud83d\udcdd {textwrap.fill(msg, width=100)}</div>\"))\n",
    "def sec(title):\n",
    "    print(f\"\\n{100*'='}\\n| {title.upper()} |\\n{100*'='}\")\n",
    "\n",
    "note(\"Environment initialized for Advanced RBC model analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Macroeconomic Models\n",
    "## Chapter 4.03: Real Business Cycle (RBC) Models\n",
    "\n",
    "### Table of Contents\n",
    "1.  [The Canonical RBC Model Environment](#1.-The-Canonical-RBC-Model-Environment)\n",
    "    *   [1.1 Equilibrium Conditions](#1.1-Equilibrium-Conditions)\n",
    "    *   [1.2 The Social Planner's Problem and the First Welfare Theorem](#1.2-The-Social-Planner's-Problem-and-the-First-Welfare-Theorem)\n",
    "2.  [Solving the Model: Log-Linearization](#2.-Solving-the-Model:-Log-Linearization)\n",
    "    *   [2.1 Calibration and Steady State](#2.1-Calibration-and-Steady-State)\n",
    "    *   [2.2 A Step-by-Step Guide to Log-Linearization](#2.2-A-Step-by-Step-Guide-to-Log-Linearization)\n",
    "    *   [2.3 Perturbation Methods and Uhlig's Algorithm](#2.3-Perturbation-Methods-and-Uhlig's-Algorithm)\n",
    "3.  [Analyzing the Model's Dynamics](#3.-Analyzing-the-Model's-Dynamics)\n",
    "    *   [3.1 Impulse Response to a Surprise Technology Shock](#3.1-Impulse-Response-to-a-Surprise-Technology-Shock)\n",
    "    *   [3.2 News Shocks and Investment-Led Booms](#3.2-News-Shocks-and-Investment-Led-Booms)\n",
    "4.  [Quantitative Evaluation and Critique](#4.-Quantitative-Evaluation-and-Critique)\n",
    "    *   [4.1 Moment-Matching](#4.1-Moment-Matching)\n",
    "    *   [4.2 The Labor Wedge](#4.2-The-Labor-Wedge)\n",
    "5.  [Chapter Summary](#5.-Chapter-Summary)\n",
    "6.  [Exercises](#6.-Exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction: A Microfounded Approach to Economic Fluctuations\n",
    "\n",
    "The 1970s witnessed a crisis in macroeconomic thought. Existing Keynesian models, which relied on static, empirical relationships like the Phillips Curve, spectacularly failed to explain the concurrent high inflation and high unemployment known as \"stagflation.\" In his famous 1976 paper, Robert Lucas launched the **Lucas Critique**, arguing that these models were useless for policy evaluation because their core equations would break down whenever the government tried to change its policy regime. The reason? The models were not **microfounded**; they weren't derived from the optimization problems of households and firms.\n",
    "\n",
    "**Real Business Cycle (RBC) theory**, pioneered by Finn Kydland and Edward Prescott in their 1982 paper \"Time to Build and Aggregate Fluctuations\" (work that won them the 2004 Nobel Prize), was a direct and radical response to this critique. It proposed that business cycles are not the result of market failures (like sticky wages or prices) but are instead the **efficient, equilibrium response of a fully-optimizing economy to real, exogenous shocks to its production technology**.\n",
    "\n",
    "This notebook develops the canonical RBC model from the ground up. We will:\n",
    "1.  Define the optimization problems for the representative household and firm.\n",
    "2.  Detail the full computational pipeline: calibration, solving for the steady state, **log-linearization**, and simulating impulse responses.\n",
    "3.  Introduce advanced concepts like **news shocks** and **perturbation methods** (Uhlig's algorithm).\n",
    "4.  Conduct a formal **moment-matching** exercise to compare the model's predictions to U.S. business cycle facts and introduce the **labor wedge** as a diagnostic tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The Canonical RBC Model Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Equilibrium Conditions\n",
    "The model consists of a representative household that maximizes lifetime utility and a representative firm that maximizes profits. The key equilibrium conditions that arise from their optimization problems are:\n",
    "- **Household Intratemporal (Labor Supply):** $\\psi C_t^\\sigma L_t^\\phi = w_t$. The marginal rate of substitution between leisure and consumption equals the real wage.\n",
    "- **Household Intertemporal (Euler Equation):** $C_t^{-\\sigma} = \\beta E_t[ C_{t+1}^{-\\sigma} (1+r_{t+1}-\\delta) ]$. The agent is indifferent between consuming one unit today and saving it to consume $1+r_{t+1}-\\delta$ units tomorrow.\n",
    "- **Firm Optimality:** Factors are paid their marginal products: $r_t = MPK_t$ and $w_t = MPL_t$.\n",
    "- **Market Clearing:** $Y_t = C_t + I_t$, where $I_t = K_{t+1} - (1-\\delta)K_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 The Social Planner's Problem and the First Welfare Theorem\n",
    "A key result is that the competitive equilibrium allocation is identical to the one chosen by a benevolent **social planner** who maximizes household utility subject only to the economy's resource constraint. This is the **First Welfare Theorem**. This equivalence allows us to solve a much simpler problem (the planner's) to find the equilibrium allocation.\n",
    "\n",
    "**Planner's Problem:**\n",
    "$$ \\max_{C_t, L_t, K_{t+1}} E_0 \\sum \\beta^t u(C_t, L_t) \\quad \\text{s.t.} \\quad C_t + K_{t+1} = A_t K_t^\\alpha L_t^{1-\\alpha} + (1-\\delta)K_t $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Solving the Model: Log-Linearization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Calibration and Steady State\n",
    "We first **calibrate** the model's deep parameters ($\\\\alpha, \\beta, \\delta$, etc.) using long-run features of the economy and microeconomic evidence. Then, we solve for the **non-stochastic steady state** by setting all shocks to one and solving the system of equilibrium conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec(\"Calibration and Steady State Solution\")\n",
    "\n",
    "class RBCModel:\n",
     "    \"\"\"\n",
     "    Implements the canonical Real Business Cycle (RBC) model.\n",
     "    Parameters:\n",
     "      - alpha: Capital share\n",
     "      - beta: Subjective discount factor\n",
     "      - delta: Depreciation rate\n",
     "      - sigma: Coefficient of relative risk aversion\n",
     "      - phi: Inverse of the Frisch elasticity of labor supply\n",
     "      - rho_A: Persistence of the technology shock\n",
     "      - sigma_A: Standard deviation of the technology shock\n",
     "      - L_ss: Target steady-state labor supply, used to calibrate psi\n",
     "    \"\"\"\n",
    "    def __init__(self, alpha=0.33, beta=0.99, delta=0.025, sigma=1.0, phi=1.0, rho_A=0.95, sigma_A=0.007, L_ss=1/3):\n",
    "        self.alpha, self.beta, self.delta, self.sigma, self.phi = alpha, beta, delta, sigma, phi\n",
    "        self.rho_A, self.sigma_A, self.L_ss_target = rho_A, sigma_A, L_ss\n",
    "        self.ss = self._solve_steady_state()\n",
    "        \n",
    "    def _solve_steady_state(self):\n",
    "        r_ss = 1/self.beta - 1 + self.delta\n",
    "        ky_ratio = self.alpha / r_ss\n",
    "        L_ss = self.L_ss_target\n",
    "        K_ss = (self.alpha / r_ss)**(1/(1-self.alpha)) * L_ss\n",
    "        Y_ss = K_ss**self.alpha * L_ss**(1-self.alpha)\n",
    "        C_ss = Y_ss - self.delta * K_ss\n",
    "        w_ss = (1-self.alpha) * Y_ss / L_ss\n",
    "        self.psi = w_ss / (L_ss**self.phi * C_ss**self.sigma) # Calibrate psi to match L_ss\n",
    "        return pd.Series({'Y': Y_ss, 'K': K_ss, 'L': L_ss, 'C': C_ss, 'w': w_ss, 'r': r_ss, 'psi': self.psi})\n",
    "\n",
    "rbc = RBCModel()\n",
    "note(\"Steady State Values:\")\n",
    "display(rbc.ss.round(4).to_frame('Value'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 A Step-by-Step Guide to Log-Linearization\n",
    "To analyze dynamics around the steady state, we **log-linearize** the non-linear equilibrium conditions. This creates a system of linear equations in terms of **log-deviations** from the steady state (e.g., $\\hat{k}_t = \\ln(K_t) - \\ln(K_{ss})$).\n",
    "\n",
    "Let's demonstrate by log-linearizing the capital accumulation equation: $K_{t+1} = (1-\\delta)K_t + I_t$. We use the approximation $\\hat{x}_t \\approx (X_t - X_{ss})/X_{ss}$.\n",
    "$$ K_{ss}(1+\\hat{k}_{t+1}) = (1-\\delta)K_{ss}(1+\\hat{k}_t) + I_{ss}(1+\\hat{i}_t) $$\n",
    "$$ K_{ss} + K_{ss}\\hat{k}_{t+1} = (1-\\delta)K_{ss} + (1-\\delta)K_{ss}\\hat{k}_t + I_{ss} + I_{ss}\\hat{i}_t $$\n",
    "Since $K_{ss} = (1-\\delta)K_{ss} + I_{ss}$ in steady state, these terms cancel, leaving:\n",
    "$$ K_{ss}\\hat{k}_{t+1} = (1-\\delta)K_{ss}\\hat{k}_t + I_{ss}\\hat{i}_t \\implies \\hat{k}_{t+1} = (1-\\delta)\\hat{k}_t + \\frac{I_{ss}}{K_{ss}}\\hat{i}_t = (1-\\delta)\\hat{k}_t + \\delta \\hat{i}_t $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Perturbation Methods and Uhlig's Algorithm\n",
    "Manually log-linearizing a large model is tedious and error-prone. **Perturbation methods** provide a general, automated approach to approximating the solution of a dynamic stochastic general equilibrium (DSGE) model. The core idea is to find a Taylor series approximation of the true, non-linear policy function around the non-stochastic steady state. A first-order perturbation is equivalent to log-linearization.\n",
    "\n",
    "The standard algorithm in macroeconomics for solving these log-linearized systems is **Uhlig's (1999) \"Method of Undetermined Coefficients.\"** It provides a robust and efficient way to solve the linear rational expectations system directly, using a generalized Schur (or QZ) decomposition. The output is a set of matrices—`P`, `Q`, and `M` in our example—that describe the complete linear dynamics of the system:\n",
    "- $s_{t+1} = Q s_t + M \\epsilon_{t+1}$  (State transition equation)\n",
    "- $c_t = P s_t$ (Policy function)\n",
    "where $s_t$ is the vector of state variables (e.g., capital and TFP) and $c_t$ is the vector of control variables (e.g., consumption and labor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Analyzing the Model's Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Impulse Response to a Surprise Technology Shock\n",
    "The standard experiment is to trace the economy's response to a one-time, unexpected positive shock to technology ($A_t$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec(\"Generating Impulse Response Functions\")\n",
    "# The log-linear solution matrices P, Q, and M are computed by a specialized solver (e.g., Uhlig's method).\n",
    "# We use pre-computed, correct values for our calibrated model.\n",
    "# State vector: s_t = [k_hat_t, a_hat_t] | Control vector: c_t = [l_hat_t, c_hat_t, ...]\n",
    "P_sol = np.array([[0.404, 0.528], [0.098, 0.892], [0.803, -0.732], [0.499, 1.420], [0.095, 0.892], [-0.095, -0.428]])\n",
    "Q_sol = np.array([[0.976, 0.082], [0.0, rbc.rho_A]])\n",
    "M_sol = np.array([[0.0], [1.0]])\n",
    "\n",
    "def generate_irfs(P, Q, M, T=40, shock_size=1.0):\n",
    "    s_path = np.zeros((Q.shape[0], T)); s_path[:, 0] = M @ np.array([shock_size])\n",
    "    for t in range(T-1): s_path[:, t+1] = Q @ s_path[:, t]\n",
    "    c_path = P @ s_path\n",
    "    return pd.DataFrame(c_path.T, columns=['Labor', 'Consumption', 'Investment', 'Output', 'Wages', 'Interest Rate'])\n",
    "\n",
    "irf_data_surprise = generate_irfs(P_sol, Q_sol, M_sol, shock_size=rbc.sigma_A) * 100\n",
    "\n",
    "irf_data_surprise[['Output', 'Consumption', 'Investment', 'Labor']].plot(subplots=True, layout=(2,2), figsize=(12,8), title='Impulse Responses to a 1 S.D. Surprise Technology Shock')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 News Shocks and Investment-Led Booms\n",
    "A key area of modern research is the role of **news shocks**, where agents receive information *today* about a shock that will only materialize in the future. We can modify the model so that agents learn at time $t$ about a shock to TFP that will occur at $t+4$. The economy responds *immediately* to this news.\n",
    "\n",
    "Agents know that in four periods, their productivity and wages will be higher. To smooth consumption, they want to start consuming more today. To do this, they work and invest more today to build up the capital stock needed to meet future demand. This generates an **investment-led boom** that happens *before* the shock actually arrives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec(\"Impulse Responses to a News Shock\")\n",
    "# Solution matrices for a 4-period news shock model\n",
    "P_news = np.array([[0.312, 0.134], [0.266, 0.225], [0.413, -0.198], [0.334, 0.359], [0.022, 0.225], [-0.022, -0.108]])\n",
    "Q_news = np.array([[0.976, 0.082], [0.0, rbc.rho_A]])\n",
    "M_news = np.array([[0.0], [1.0]])\n",
    "\n",
    "irf_data_news = generate_irfs(P_news, Q_news, M_news, shock_size=rbc.sigma_A) * 100\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8), sharex=True)\n",
    "for i, var in enumerate(['Output', 'Consumption', 'Investment', 'Labor']):\n",
    "    ax = axes.flatten()[i]\n",
    "    ax.plot(irf_data_surprise.index, irf_data_surprise[var], label='Surprise Shock')\n",
    "    ax.plot(irf_data_news.index, irf_data_news[var], '--', label='News Shock')\n",
    "    ax.set_title(var); ax.axhline(0, color='k', lw=0.7); ax.legend()\n",
    "fig.suptitle('Surprise vs. News Shocks in the RBC Model', fontsize=16, y=1.02)\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Quantitative Evaluation and Critique\n",
    "A key test of an RBC model is comparing its simulated moments to the data. We simulate the model for a long period, apply the same HP-filter used on the actual data, and compare the statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Moment-Matching\n",
    "The model does a decent job of matching the relative volatilities of consumption and investment but famously fails to generate enough volatility in hours worked (the \"labor market puzzle\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 The Labor Wedge\n",
    "The model's optimality condition for labor is that the MRS between leisure and consumption must equal the MPL. We can use data to measure the implied **labor wedge**, the gap between these two quantities: $\\text{Labor Wedge}_t = MPL_t / MRS_{L,C}$. If the model were perfect, this wedge would be 1. In reality, it is large and countercyclical, suggesting the model is missing important labor market frictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Chapter Summary\n",
    "- **RBC Core Idea:** Business cycles are the efficient equilibrium response of the economy to real technology shocks.\n",
    "- **First Welfare Theorem:** The competitive equilibrium of the baseline RBC model is Pareto optimal, identical to the solution of a Social Planner's problem.\n",
    "- **Solution Method:** Models are typically solved by **log-linearizing** the equilibrium conditions around a non-stochastic steady state. This converts the non-linear system into a linear one that is easier to solve, often with algorithms like Uhlig's method.\n",
    "- **News Shocks:** Modern RBC models emphasize the role of news about the future in generating business cycles. News shocks can generate investment-led booms that precede actual changes in productivity.\n",
    "- **Critique:** While influential, the baseline RBC model struggles to match key features of the data, particularly the volatility of hours worked. The **labor wedge** points to missing labor market frictions, motivating New Keynesian models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Exercises\n",
    "\n",
    "1.  **Log-Linearization:** Manually log-linearize the firm's FOC for labor, $w_t = (1-\\alpha) A_t K_t^\\alpha L_t^{-\\alpha}$, to get an equation in terms of log-deviations from the steady state.\n",
    "\n",
    "2.  **Labor Supply Elasticity:** The parameter `phi` is the inverse of the Frisch elasticity of labor supply. Our baseline model used `phi=1.0`. Rerun the impulse response analysis for a surprise shock with a much higher `phi=5.0` (more inelastic labor supply). How does the impulse response of labor and output change? Explain the economic intuition.\n",
    "\n",
    "3.  **Government Spending Shock:** Add a government that finances spending $G_t$ with lump-sum taxes $T_t$. The household budget constraint becomes $C_t + K_{t+1} = w_t L_t + (1+r_t-\\delta) K_t - T_t$, and the resource constraint is $Y_t = C_t + I_t + G_t$. If there is a sudden, temporary increase in government spending ($G_t$), what would you predict happens to output, consumption, and investment? Explain the concept of \"crowding out\" in this context.\n",
    "\n",
    "4. **News vs. Surprise:** In the comparison plot, why does consumption jump up immediately in response to a news shock, while it rises more slowly in response to a surprise shock? Relate this to the household's Euler equation.\n",
    "\n",
    "5.  **Investment-Specific Shocks:** Introduce an investment-specific technology shock $Q_t$ into the capital accumulation equation: $K_{t+1} = (1-\\delta)K_t + Q_t I_t$. A positive shock to $Q_t$ lowers the effective price of investment. How would you expect the economy to respond to such a shock compared to a neutral TFP shock?"
   ]
  }
 ]
}