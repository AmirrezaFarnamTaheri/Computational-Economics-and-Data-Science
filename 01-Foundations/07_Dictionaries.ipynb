{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Environment Setup ===\n",
    "import os, sys, math, time, random, json, textwrap, warnings, timeit\n",
    "from collections import defaultdict, Counter, ChainMap\n",
    "from types import MappingProxyType\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "\n",
    "# --- Configuration ---\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams[\"figure.dpi\"] = 130\n",
    "\n",
    "# --- Utility Functions ---\n",
    "def note(msg, **kwargs):\n",
    "    \"\"\"Prints a formatted message with a notebook icon.\"\"\"\n",
    "    formatted_msg = textwrap.fill(msg, width=100, subsequent_indent='   ')\n",
    "    print(f\"\\n\ud83d\udcdd {formatted_msg}\", **kwargs)\n",
    "def sec(title):\n",
    "    \"\"\"Prints a formatted section title for code blocks.\"\"\"\n",
    "    print(f\"\\n{100*'='}\\n| {title.upper()} |\\n{100*'='}\")\n",
    "\n",
    "note(\"Environment initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Foundations\n",
    "## Chapter 1.7: Dictionaries and Hash Maps: The Engine of Modern Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction: The Most Important Data Structure\n",
    "\n",
    "The dictionary, `dict`, is arguably Python's most important data structure. It is the fundamental implementation behind many core features of the language: object attributes are stored in an instance's `__dict__`, module namespaces are dictionaries, and class methods are looked up in a class's dictionary. Its defining characteristic is exceptional performance: insertion, deletion, and lookup operations have an **O(1) average time complexity**, meaning their speed is independent of the dictionary's size. This remarkable efficiency is the result of its underlying implementation as a **hash map** (also known as a hash table).\n",
    "\n",
    "This chapter examines the `dict`, moving beyond basic key-value usage to explore the internal mechanics of its hash map implementation. We will cover the critical requirement of key immutability, modern usage patterns, and the specialized, high-performance dictionary subclasses provided by the `collections` module. A firm grasp of dictionary mechanics is essential for writing efficient, robust, and idiomatic Python for computational research, especially when dealing with the sparse representations of objects (e.g., utility functions defined over a sparse grid) that are common in economics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The Hash Map Mechanism\n",
    "\n",
    "A hash map achieves its speed by using a **hash function** to convert a key into an integer. This integer is then used to compute an index (a \"slot\" or \"bucket\") in an underlying array where the associated value is stored. This direct computation of a storage location, rather than a linear search through the keys, is the source of its O(1) performance.\n",
    "\n",
    "The process for `my_dict[key] = value` is illustrated below:\n",
    "1.  **Hashing:** Python computes `hash(key)`, which returns an integer (the hash value).\n",
    "2.  **Indexing:** This hash value is used to calculate an index into an internal array of slots. To ensure the index is within the array bounds, a common method is to use the modulo operator: `index = hash(key) % array_size`.\n",
    "3.  **Storage:** The key-value pair (or a reference to it) is stored at that index. If that index is already occupied (a **hash collision**), Python uses a probing algorithm to find the next available slot.\n",
    "\n",
    "![Hash Map Mechanism](../images/png/1.7-hash-map.png)\n",
    "\n",
    "A lookup for `my_dict[key]` follows the same process: hash the key, compute the initial index, and if the key stored there doesn't match, probe for the next slot until the key is found or an empty slot is encountered.\n",
    "\n",
    "#### 1.1 The Hashable Requirement and Immutability\n",
    "For this system to work, a dictionary key must be **hashable**. An object is hashable if it meets two criteria:\n",
    "1.  It has a `__hash__` method that returns an integer. **This hash value must remain constant throughout the object's lifetime.**\n",
    "2.  It has an `__eq__` method to compare for value equality.\n",
    "\n",
    "The fundamental invariant of hashing is: **if `a == b`, then it must be true that `hash(a) == hash(b)`**. \n",
    "\n",
    "This is why only **immutable** types can be used as dictionary keys. If a key's value could change after being inserted into a dictionary, its hash value would also change, and the key would become \"lost\"â€”unfindable at the location computed from its original hash. All of Python's built-in immutable types (`str`, `int`, `float`, `bool`, `tuple`) are hashable. Mutable types like `list` and `dict` are not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec(\"Why Lists Cannot Be Dictionary Keys\")\n",
    "mutable_key = [1, 2] # A list is mutable\n",
    "try:\n",
    "    my_dict = {mutable_key: 'value'}\n",
    "except TypeError as e:\n",
    "    note(f\"Python correctly raises an error for mutable keys: {e}\")\n",
    "\n",
    "immutable_key = (1, 2) # A tuple is immutable\n",
    "my_dict = {immutable_key: 'value'}\n",
    "note(f\"Tuples, being immutable, are valid keys: {my_dict}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The `frozenset`: A Hashable Set\n",
    "Just as a `tuple` is an immutable version of a `list`, a `frozenset` is an immutable version of a `set`. Because they are immutable and their contents cannot change, frozensets are hashable and can be used as dictionary keys. This is useful when you need to use a collection of unique items as a key, for example, to map a set of model features to a specific coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = frozenset(['age', 'education', 'income'])\n",
    "coefficient_map = {feature_set: 0.75}\n",
    "\n",
    "note(f\"A frozenset can be used as a dictionary key:\")\n",
    "print(coefficient_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Hash Collisions, Load Factor, and Performance Degradation\n",
    "\n",
    "A **hash collision** occurs when two different keys produce the same hash value (and thus map to the same initial slot in the array). Python resolves this through a process called **open addressing** with a pseudo-random probing sequence. If the initial slot is already occupied by a different key, Python applies a deterministic perturbation to the hash value to calculate a new slot, and probes that one. This continues until an empty slot is found.\n",
    "\n",
    "The **load factor** of a hash table is the ratio of occupied slots to the total number of slots. As the load factor increases, the probability of collisions rises, and lookup times can degrade. To maintain O(1) average performance, Python's dictionaries are resized to a larger array once the load factor exceeds a certain threshold (typically 2/3). This resizing is an O(n) operation, but because it happens infrequently, the **amortized** cost of insertion remains O(1).\n",
    "\n",
    "However, in the worst-case scenario (e.g., a deliberately crafted set of keys that all collide), the probing sequence can become long, and performance for those keys can degrade towards O(n). This is why Python uses a randomized hash function for strings to make such collision attacks more difficult.\n",
    "\n",
    "**The Modern, Ordered Dictionary (Python 3.7+):**\n",
    "A major evolution in Python was making dictionaries **insertion-ordered** by default (this was formalized as a language feature in Python 3.7). This was achieved by changing the internal structure. A modern dictionary uses two arrays, which provides the best of both worlds:\n",
    "1.  A **sparse `indices` array** (the hash table proper) that stores indices into the second array. This allows for O(1) lookups.\n",
    "2.  A **dense `entries` array** that stores the actual `(hash, key, value)` tuples in the order they were inserted. This allows for ordered iteration.\n",
    "\n",
    "![Modern Dictionary Internals](../images/png/1.7-ordered-dict.png)\n",
    "\n",
    "As the diagram shows, a lookup hashes the key to find a position in the sparse `indices` array, which then points to the correct location in the dense `entries` array. Iteration, however, simply walks down the dense `entries` array, preserving the original insertion order. This hybrid structure, while using slightly more memory, provides both fast lookups and predictable ordering, a feature so valuable it became a core part of the language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Performance: O(1) vs. O(n) in Practice\n",
    "The theoretical difference between constant time O(1) and linear time O(n) is not academic; it has dramatic real-world consequences for large datasets. A `dict` lookup takes roughly the same amount of time whether the dictionary has 10 items or 10 million. A `list` lookup (`value in my_list`) requires scanning the list from the beginning, so its time scales linearly with the size of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec(\"Timing List vs. Dictionary Lookups\")\n",
    "N = 1_000_000\n",
    "data_list = list(range(N))\n",
    "data_dict = {k: k for k in range(N)}\n",
    "search_term = N - 1 # Search for the last element (worst case for list)\n",
    "\n",
    "list_setup = f\"import random; data = list(range({N}))\"\n",
    "dict_setup = f\"import random; data = {{k:k for k in range({N})}}\"\n",
    "search_code = f\"term = {search_term}; term in data\"\n",
    "\n",
    "note(\"Timing list lookup (O(n)):\")\n",
    "list_time = timeit.timeit(search_code, setup=list_setup, number=10)\n",
    "print(f\"  -> Time taken: {list_time:.6f} seconds\")\n",
    "\n",
    "note(\"Timing dict lookup (O(1)):\")\n",
    "dict_time = timeit.timeit(search_code, setup=dict_setup, number=10)\n",
    "print(f\"  -> Time taken: {dict_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Idiomatic Dictionary Usage\n",
    "\n",
    "Fluent Python programmers leverage several powerful patterns for creating and manipulating dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Dictionary Comprehensions\n",
    "Similar to list comprehensions, **dictionary comprehensions** provide a concise and readable syntax for creating dictionaries from iterables. They are often used with `zip` to combine separate lists of keys and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec(\"Creating Dictionaries with Comprehensions\")\n",
    "country_codes = ['USA', 'DEU', 'JPN']\n",
    "gdp_data = [25.46, 4.07, 4.23] # In trillions USD\n",
    "\n",
    "# Create a dictionary mapping country codes to GDP\n",
    "gdp_map = {code: gdp for code, gdp in zip(country_codes, gdp_data)}\n",
    "print(f\"Created dictionary: {gdp_map}\")\n",
    "\n",
    "# Use a comprehension to create an inverted dictionary\n",
    "gdp_to_country = {gdp: code for code, gdp in gdp_map.items()}\n",
    "print(f\"Inverted dictionary: {gdp_to_country}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Merging Dictionaries\n",
    "As of Python 3.9, the union operators `|` (merge) and `|=` (update-in-place) provide a clean, readable syntax for combining dictionaries. When keys overlap, the value from the right-hand dictionary prevails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec(\"Modern Dictionary Merging (Python 3.9+)\")\n",
    "default_params = {'solver': 'newton', 'tolerance': 1e-6, 'verbose': False}\n",
    "user_params = {'tolerance': 1e-8, 'max_iterations': 1000}\n",
    "\n",
    "# The | operator creates a new dictionary\n",
    "final_params = default_params | user_params\n",
    "print(f\"Default parameters: {default_params}\")\n",
    "print(f\"User parameters:    {user_params}\")\n",
    "print(f\"Final parameters:   {final_params}\")\n",
    "note(\"The 'tolerance' value from user_params (the right-hand side) overwrote the default value.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Handling Missing Keys\n",
    "A common task is to read or update a dictionary key that may not exist. Attempting to access a missing key directly with `my_dict['key']` raises a `KeyError`. There are several idiomatic ways to handle this, each suited to a different situation.\n",
    "\n",
    "- **`d.get(key, default)`**: The preferred way to look up a key that might be missing. It returns the corresponding value if the key exists, or a specified default value (which itself defaults to `None`) if it doesn't. It never raises a `KeyError` and never modifies the dictionary.\n",
    "\n",
    "- **`d.setdefault(key, default)`**: This method is more specialized. It also retrieves the key's value, but if the key is missing, it **inserts** the key with the specified default value into the dictionary and then returns that default value. It is useful when you want to both retrieve a value and ensure it exists in the dictionary afterward.\n",
    "\n",
    "- **`collections.defaultdict`**: This dictionary subclass is the most powerful tool for aggregating or grouping data. You provide a factory function (e.g., `list`, `int`, `set`) during its creation. When a missing key is accessed for the first time, the factory is automatically called to create and insert a default value for that key, which is then returned. This avoids the need for manual checks when building up collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec(\"Idiomatic Ways to Handle Missing Keys\")\n",
    "\n",
    "model_config = {'learning_rate': 0.01}\n",
    "\n",
    "note(\"Use .get() for safe lookups without modification.\")\n",
    "batch_size = model_config.get('batch_size', 32) # Safely get 'batch_size', defaulting to 32\n",
    "print(f\"  Batch size is: {batch_size}\")\n",
    "print(f\"  Original config is unchanged: {model_config}\")\n",
    "\n",
    "note(\"Use .setdefault() to retrieve a key and ensure it exists.\")\n",
    "optimizer = model_config.setdefault('optimizer', 'Adam') # Get 'optimizer', setting it to 'Adam' if absent\n",
    "print(f\"  Optimizer is: {optimizer}\")\n",
    "print(f\"  Config was modified: {model_config}\")\n",
    "\n",
    "note(\"Use defaultdict for efficient grouping/aggregation.\")\n",
    "# Application: Inverting a dictionary to map grades to students\n",
    "grades = {'Alice': 'A', 'Bob': 'C', 'Charlie': 'A', 'David': 'B'}\n",
    "students_by_grade = defaultdict(list)\n",
    "for student, grade in grades.items():\n",
    "    # If `grade` is a new key, defaultdict calls list() to create an empty list first.\n",
    "    # This avoids a manual `if grade not in students_by_grade: ...` check.\n",
    "    students_by_grade[grade].append(student)\n",
    "\n",
    "print(f\"Inverted mapping: {json.dumps(dict(students_by_grade), indent=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Dictionary Views and Set Operations\n",
    "The dictionary methods `.keys()`, `.values()`, and `.items()` do not return lists. They return special **view objects**. A view is a dynamic window into the dictionary's entries. If the dictionary changes, the view reflects these changes immediately. \n",
    "\n",
    "Key views and item views also behave like sets, allowing for highly efficient set-based operations like intersection (`&`), union (`|`), and difference (`-`). This is very useful for comparing the parameters or features of different models or datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec(\"Dictionary Views and Set Operations\")\n",
    "model1_params = {'alpha': 0.3, 'beta': 0.99, 'gamma': 0.5}\n",
    "model2_params = {'alpha': 0.3, 'beta': 0.95, 'delta': 0.025}\n",
    "\n",
    "keys1 = model1_params.keys()\n",
    "keys2 = model2_params.keys()\n",
    "\n",
    "print(f\"Model 1 Keys: {keys1}\")\n",
    "print(f\"Model 2 Keys: {keys2}\")\n",
    "\n",
    "note(\"Using set operations on key views:\")\n",
    "print(f\"  Common parameters (intersection): {keys1 & keys2}\")\n",
    "print(f\"  All unique parameters (union):    {keys1 | keys2}\")\n",
    "print(f\"  Parameters only in Model 1:       {keys1 - keys2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Specialized Dictionaries in `collections`\n",
    "\n",
    "The `collections` module provides several highly-optimized dictionary subclasses for specialized use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 `collections.Counter`: Frequency Maps\n",
    "\n",
    "A `Counter` is a `dict` subclass specifically designed for counting hashable objects. It provides a convenient way to create frequency distributions and includes useful methods like `most_common()`. It also supports multiset arithmetic, allowing you to combine counters in meaningful ways.\n",
    "\n",
    "**Economic Application:** Analyzing the frequency of different industry sectors in a dataset of firms, or counting word frequencies in a central bank policy document to measure textual similarity using techniques like cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec(\"Frequency Counting and Cosine Similarity with Counter\")\n",
    "\n",
    "doc1_words = ['inflation', 'risk', 'growth', 'inflation', 'labor', 'risk']\n",
    "doc2_words = ['growth', 'jobs', 'inflation', 'risk', 'growth']\n",
    "\n",
    "counts1 = Counter(doc1_words)\n",
    "counts2 = Counter(doc2_words)\n",
    "\n",
    "note(\"Use Counter to create term-frequency vectors:\")\n",
    "print(f\"Document 1 Counts: {counts1}\")\n",
    "print(f\"Document 2 Counts: {counts2}\")\n",
    "\n",
    "def cosine_similarity(c1, c2):\n",
    "    \"\"\"Calculates the cosine similarity between two Counter vectors.\"\"\"\n",
    "    # Get the set of all unique words across both documents\n",
    "    all_words = c1.keys() | c2.keys()\n",
    "    \n",
    "    # Compute dot product and magnitudes\n",
    "    dot_product = sum(c1[word] * c2[word] for word in all_words)\n",
    "    mag1 = math.sqrt(sum(c1[word]**2 for word in all_words))\n",
    "    mag2 = math.sqrt(sum(c2[word]**2 for word in all_words))\n",
    "    \n",
    "    return dot_product / (mag1 * mag2) if (mag1 * mag2) != 0 else 0\n",
    "\n",
    "similarity = cosine_similarity(counts1, counts2)\n",
    "note(f\"The cosine similarity between the two documents is {similarity:.4f}. This provides a quantitative measure of their textual similarity.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 `collections.ChainMap`: Hierarchical Configurations\n",
    "A `ChainMap` groups multiple dictionaries into a single, updatable view. Lookups search the underlying mappings sequentially until a key is found. This is perfect for managing hierarchical configurations.\n",
    "\n",
    "**Crucial Behavior:** Writes, updates, and deletions (`config['key'] = value`) operate *only* on the **first** mapping in the chain. This allows you to temporarily override settings without modifying the underlying default dictionaries.\n",
    "\n",
    "**Economic Application:** Managing parameters for a complex economic model. You can have a dictionary of global default parameters, another with scenario-specific parameters, and a third with temporary runtime overrides. `ChainMap` provides a clean, logical view of this parameter stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec(\"Hierarchical Configurations with ChainMap\")\n",
    "\n",
    "def run_model(params):\n",
    "    \"\"\"A dummy function that simulates running a model with a given config.\"\"\"\n",
    "    print(f\"  Running model with beta={params['beta']:.2f}, delta={params['delta']:.3f}, rho={params['rho']:.2f}\")\n",
    "\n",
    "global_defaults = {'beta': 0.99, 'delta': 0.025, 'rho': 0.95, 'grid_size': 100}\n",
    "high_impatience_scenario = {'beta': 0.90} # Scenario where agents are very impatient\n",
    "\n",
    "# The search order is: scenario -> defaults\n",
    "config = ChainMap(high_impatience_scenario, global_defaults)\n",
    "\n",
    "note(\"Running the 'high impatience' scenario:\")\n",
    "run_model(config)\n",
    "print(f\"- Beta is read from the first map in the chain: {config['beta']}\")\n",
    "print(f\"- Delta is not in the first map, so it's read from the second: {config['delta']}\")\n",
    "\n",
    "note(\"To run a sensitivity test, we can add a temporary, empty map to the front.\")\n",
    "# .new_child() creates a new ChainMap with a new empty dict at the front.\n",
    "sensitivity_config = config.new_child()\n",
    "print(f\"Current config maps: {sensitivity_config.maps}\")\n",
    "\n",
    "note(\"Writes and updates ONLY affect the first mapping.\")\n",
    "sensitivity_config['rho'] = 0.5 # A temporary override\n",
    "print(\"Running sensitivity analysis with rho=0.5:\")\n",
    "run_model(sensitivity_config)\n",
    "\n",
    "print(f\"- The new rho value is only in the first map: {sensitivity_config.maps[0]}\")\n",
    "print(f\"- The underlying scenario map is unchanged: {sensitivity_config.maps[1]}\")\n",
    "\n",
    "note(\"After the sensitivity run, we can discard the temporary config.\")\n",
    "print(\"The original config is unaffected:\")\n",
    "run_model(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Advanced Patterns for Robust Code\n",
    "\n",
    "Beyond the basics, several advanced patterns are crucial for building large-scale, maintainable computational projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Encapsulation with Read-Only Views\n",
    "A common challenge in object-oriented design is exposing an object's internal state (e.g., a configuration dictionary) without allowing external code to modify it accidentally. The `types.MappingProxyType` is the standard Python solution. It wraps a dictionary in a read-only view. Any attempt to modify the proxy will raise a `TypeError`, protecting the integrity of the original object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec(\"Protecting Internal State with MappingProxyType\")\n",
    "class Model:\n",
    "    def __init__(self, params):\n",
    "        self._params = dict(params)\n",
    "        # Expose a read-only proxy, not the actual dictionary\n",
    "        self.params = MappingProxyType(self._params)\n",
    "\n",
    "    def update_beta(self, new_beta):\n",
    "        \"\"\"A controlled method for updating an internal parameter.\"\"\"\n",
    "        self._params['beta'] = new_beta\n",
    "        print(f\"[Model internal] Beta updated to {new_beta}\")\n",
    "\n",
    "m = Model({'alpha': 0.3, 'beta': 0.99})\n",
    "print(f\"Initial parameters (read-only view): {m.params}\")\n",
    "print(f\"Can read beta: {m.params['beta']}\")\n",
    "\n",
    "note(\"Attempting to modify the exposed parameters directly fails:\")\n",
    "try:\n",
    "    m.params['beta'] = 0.95\n",
    "except TypeError as e:\n",
    "    print(f\"-> Caught expected error: {e}\")\n",
    "\n",
    "note(\"The proxy is dynamic: it reflects changes made through controlled methods.\")\n",
    "m.update_beta(0.98)\n",
    "print(f\"Parameters view now shows: {m.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Structural Pattern Matching (Python 3.10+)\n",
    "The `match...case` statement provides a powerful way to deconstruct objects, including dictionaries, based on their structure. It is more expressive and often safer than a complex chain of `if...elif...else` statements, as it can ensure that all possible cases are handled.\n",
    "\n",
    "**Economic Application:** Parsing complex configuration dictionaries for a simulation, where different solvers might require different sets of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec(\"Pattern Matching for Config Dispatch\")\n",
    "\n",
    "def setup_solver(config: dict):\n",
    "    match config:\n",
    "        case {\"solver\": \"VFI\", \"grid_size\": g, \"tolerance\": t}:\n",
    "            print(f\"Setting up Value Function Iteration with grid={g}, tol={t}\")\n",
    "        case {\"solver\": \"EGM\", \"grid_size\": g, \"max_iter\": m, **rest}:\n",
    "            print(f\"Setting up Endogenous Grid Method with grid={g}, max_iter={m}\")\n",
    "            print(f\"  (Other params: {rest})\")\n",
    "        case {\"solver\": s}:\n",
    "            print(f\"Warning: Unknown solver '{s}'. Using defaults.\")\n",
    "        case _:\n",
    "            print(\"Error: Invalid configuration object.\")\n",
    "\n",
    "note(\"Dispatching based on different config dictionaries:\")\n",
    "setup_solver({\"solver\": \"VFI\", \"grid_size\": 200, \"tolerance\": 1e-7})\n",
    "setup_solver({\"solver\": \"EGM\", \"grid_size\": 500, \"max_iter\": 1000, 'verbose': True})\n",
    "setup_solver({\"solver\": \"PolicyIteration\"})\n",
    "setup_solver({'model_type': 'RBC'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Dictionaries and Object Internals: `__dict__` and `__slots__`\n",
    "\n",
    "As mentioned, dictionaries are central to Python's object model. By default, the attributes of a class instance are stored in a special dictionary called `__dict__`. This is what makes Python so flexible, as you can add new attributes to an instance at any time. \n",
    "\n",
    "However, for performance-critical applications where you might create millions of objects (e.g., agents in a simulation), the memory overhead of a `__dict__` for every object can be substantial. The `__slots__` feature provides a memory optimization by telling Python *not* to use a `__dict__` and to only allocate space for a fixed set of attributes. This trades flexibility for a significantly smaller memory footprint and faster attribute access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec(\"__dict__ vs. __slots__ Memory Optimization\")\n",
    "\n",
    "class AgentWithDict:\n",
    "    def __init__(self, wealth, age):\n",
    "        self.wealth = wealth\n",
    "        self.age = age\n",
    "\n",
    "class AgentWithSlots:\n",
    "    __slots__ = ['wealth', 'age']\n",
    "    def __init__(self, wealth, age):\n",
    "        self.wealth = wealth\n",
    "        self.age = age\n",
    "\n",
    "a_dict = AgentWithDict(100.0, 40)\n",
    "a_slots = AgentWithSlots(100.0, 40)\n",
    "\n",
    "note(f\"Instance with __dict__ has an attribute dictionary: {a_dict.__dict__}\")\n",
    "note(\"Memory for instance with __dict__: {sys.getsizeof(a_dict) + sys.getsizeof(a_dict.__dict__)} bytes\")\n",
    "note(f\"Memory for instance with __slots__: {sys.getsizeof(a_slots)} bytes\")\n",
    "\n",
    "note(\"Attempting to add a new attribute to the slotted instance fails:\")\n",
    "try:\n",
    "    a_slots.is_employed = True\n",
    "except AttributeError as e:\n",
    "    print(f\"-> Caught expected error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Exercises\n\n",
    "#### Exercise 1: Choosing the Right Tool for Default Values\n",
    "You are processing a list of sales transactions `transactions = [{'id': 1, 'region': 'NA'}, {'id': 2, 'region': 'EU'}, {'id': 3, 'region': 'NA'}]`. You want to create a dictionary mapping each region to a count of its transactions. This requires initializing the count for a new region to 0.\n",
    "- **Task:** Implement this counting logic three times:\n",
    "  a. Using a standard `dict` and the `.get()` method.\n",
    "  b. Using a standard `dict` and the `.setdefault()` method.\n",
    "  c. Using a `defaultdict(int)`.\n",
    "- **Analysis:** Briefly explain which approach you find most elegant and why. Which is likely most performant for a very large list of transactions?\n\n",
    "#### Exercise 2: `ChainMap` for Model Scenarios\n",
    "You have a `baseline_params` dictionary for a macroeconomic model. Create two alternative scenario dictionaries, `high_inflation_shock` and `low_productivity_shock`, each changing just one or two parameters from the baseline. Use `ChainMap` to create `config_high_inf` and `config_low_prod` that represent the full parameter sets for each scenario without duplicating the baseline parameters. Demonstrate that you can access both an overridden and an unchanged parameter correctly from one of the configurations.\n\n",
    "#### Exercise 3: Comparing Word Frequencies with `Counter`\n",
    "- **Task:** Using the `counts1` and `counts2` `Counter` objects from Section 3.1, find the words that are common to both documents (`intersection`) and the words that appear in either document but not both (`symmetric difference`).\n",
    "- **Hint:** `Counter` keys behave like sets. You can use the `&` operator for intersection and `^` for symmetric difference on the keys of the counters.\n\n",
    "#### Exercise 4: Performance Deep Dive\n",
    "- **Task:** Re-run the list vs. dict lookup timing experiment from Section 1.3, but this time search for an element at the *beginning* of the list (`search_term = 0`). \n",
    "- **Analysis:** Does the relative performance change? Explain your results in terms of the Big-O complexity of the lookup operations for each data structure.\n\n",
    "--- \n",
    "\n",
    "### Challenge Exercise: Building an Inverted Index\n",
    "\n",
    "An **inverted index** is a core data structure used in search engines. It maps content, such as words, to a list of locations where they can be found. This exercise simulates building one for a small corpus of economic policy documents.\n",
    "\n",
    "**Objective:** Create an inverted index that maps each unique word to a list of document IDs where that word appears.\n",
    "\n",
    "1.  **The Data:**\n",
    "    ```python\n",
    "    corpus = {\n",
    "        'doc1': \"The Fed raised interest rates due to inflation concerns.\",\n",
    "        'doc2': \"Labor market remains strong, but inflation is a primary risk.\",\n",
    "        'doc3': \"Geopolitical risk could impact economic growth.\"\n",
    "    }\n",
    "    ```\n",
    "\n",
    "2.  **Build the Index:**\n",
    "    - **Task:** Create an inverted index using a `defaultdict(list)`. Iterate through each document in the corpus. For each document, you'll need to:\n",
    "        a. Convert the text to lowercase.\n",
    "        b. Remove punctuation (e.g., using `str.replace('.', '').replace(',', '')`).\n",
    "        c. Split the text into a list of words.\n",
    "        d. Iterate through the words. For each word, append the current `doc_id` (e.g., 'doc1') to the list associated with that word in your inverted index.\n",
    "\n",
    "3.  **Analyze the Index:**\n",
    "    - Print the inverted index for the words 'inflation', 'risk', and 'growth'.\n",
    "\n",
    "4.  **Bonus: Add Word Counts:**\n",
    "    - Modify your inverted index. Instead of a list of document IDs, the value for each word should be another dictionary that maps a `doc_id` to the *frequency* of that word within that document. The final structure should look like: `{'inflation': {'doc1': 2, 'doc2': 1}, ...}`.\n",
    "    - **Hint:** You might find a `defaultdict(Counter)` to be a particularly elegant tool for this task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}