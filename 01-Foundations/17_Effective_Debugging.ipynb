{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# === Environment Setup ===\n",
    "import os, sys, math, time, random, json, textwrap, warnings, logging\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "# line_profiler is a powerful tool for performance analysis.\n",
    "# It needs to be installed: pip install line_profiler ipdb\n",
    "%load_ext line_profiler\n",
    "\n",
    "# --- Configuration ---\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams.update({'font.size': 12, 'figure.figsize': (8, 5), 'figure.dpi': 130})\n",
    "np.set_printoptions(suppress=True, linewidth=120, precision=4)\n",
    "# Configure basic logging to print to the console\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# --- Utility Functions ---\n",
    "def note(msg, **kwargs):\n",
    "    print(f\"\\n📝 {textwrap.fill(msg, width=100, subsequent_indent='   ')}\", **kwargs)\n",
    "def sec(title):\n",
    "    print(f\"\\n{100*'='}\\n| {title.upper()} |\\n{100*'='}\")\n",
    "\n",
    "note(\"Environment initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Foundations\n",
    "## Chapter 1.16: A Guide to Effective Debugging and Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction: Debugging as a Scientific Process\n",
    "\n",
    "An unspoken truth of computational work is that you will spend far more time debugging your code than writing it. A bug is simply a difference between what you *think* your code is doing and what it is *actually* doing. Therefore, **debugging is the process of closing that gap in understanding.** It is not a haphazard process of randomly changing things; it is a systematic, scientific investigation into the behavior of a program.\n",
    "\n",
    "This chapter provides a guide to the tools and, more importantly, the mindset required for effective debugging. We will frame this process as a direct application of the scientific method:\n",
    "1.  **Observe & Characterize:** The program fails. What is the exact failure? (Reading the traceback).\n",
    "2.  **Isolate & Reproduce:** Create a minimal, reproducible example (MRE) that triggers the bug reliably.\n",
    "3.  **Formulate a Hypothesis:** Based on the evidence, what do you think is causing the bug?\n",
    "4.  **Experiment & Inspect:** Test your hypothesis by inspecting the program's state with a debugger or logging.\n",
    "5.  **Fix & Verify:** Implement a fix and, crucially, write a test to confirm the fix and prevent regressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Case Study: A Buggy Asset Pricing Simulation\n",
    "\n",
    "Throughout this chapter, we will investigate a function designed to simulate the price path of a simple binomial asset pricing model. The function is seeded with several bugs that we will uncover and fix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_asset_price_buggy(p0, mu, sigma, T, dt, seed=None):\n",
    "    \"\"\"Simulates an asset price path using a simple binomial model.\n",
    "    \n",
    "    Args:\n",
    "        p0 (float): Initial price.\n",
    "        mu (float): Expected return (drift).\n",
    "        sigma (float): Volatility.\n",
    "        T (int): Total time periods.\n",
    "        dt (float): Time step size.\n",
    "        seed (int, optional): Random seed for reproducibility.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n_steps = int(T / dt)\n",
    "    price_path = np.zeros(n_steps)\n",
    "    price_path[0] = p0\n",
    "    \n",
    "    # Bug 1: Off-by-one error in loop range\n",
    "    for t in range(n_steps):\n",
    "        # Bug 2: Incorrect random sampling (should be -1 or 1)\n",
    "        z = rng.standard_normal(1) \n",
    "        # Bug 3: Incorrect formula for price update\n",
    "        price_path[t+1] = price_path[t] * (mu*dt + sigma*z*np.sqrt(dt))\n",
    "        \n",
    "    return price_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Observe and Characterize the Failure (The Traceback)\n",
    "The first step is to run the code and observe the failure. The primary tool for this is the **traceback**.\n",
    "\n",
    "A traceback is not an error message to be feared; it is the single most important piece of evidence you have. It tells you the *type* of error (`IndexError`), *where* it happened (line 22), and the sequence of function calls that led to it. **Always read a traceback from the bottom up.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec(\"Observation 1: The First Crash\")\n",
    "note(\"Calling the function with standard parameters...\")\n",
    "try:\n",
    "    simulate_asset_price_buggy(p0=100, mu=0.05, sigma=0.2, T=1, dt=0.1, seed=42)\n",
    "except IndexError as e:\n",
    "    print(f\"  --> Caught expected error: {e}\")\n",
    "    note(\"The traceback points to `price_path[t+1] = ...`. This is an `IndexError`, meaning we tried to access an index that doesn't exist. This suggests the loop runs one time too many.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Formulate a Hypothesis and Experiment\n",
    "\n",
    "- **Hypothesis 1:** The loop `for t in range(n_steps)` runs from `t = 0` to `t = n_steps - 1`. On the last iteration, `t+1` becomes `n_steps`, which is an invalid index for an array of size `n_steps` (valid indices are `0` to `n_steps - 1`).\n",
    "- **Experiment:** The loop should only run up to the second-to-last element. We can fix this by changing the loop range to `range(n_steps - 1)`.\n",
    "- **Tool:** Simple code modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_asset_price_v2(p0, mu, sigma, T, dt, seed=None):\n",
    "    \"\"\"Version 2: Fixed the loop range.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n_steps = int(T / dt)\n",
    "    price_path = np.zeros(n_steps)\n",
    "    price_path[0] = p0\n",
    "    \n",
    "    # Fix 1: Corrected loop range\n",
    "    for t in range(n_steps - 1):\n",
    "        z = rng.standard_normal(1) \n",
    "        # The formula is still wrong!\n",
    "        price_path[t+1] = price_path[t] * (mu*dt + sigma*z*np.sqrt(dt))\n",
    "        \n",
    "    return price_path\n",
    "\n",
    "sec(\"Experiment 1: Testing the Fix\")\n",
    "path_v2 = simulate_asset_price_v2(p0=100, mu=0.05, sigma=0.2, T=1, dt=0.1, seed=42)\n",
    "note(\"Function now runs without crashing. Let's inspect the output.\")\n",
    "print(path_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Observe a New Failure (The Silent Bug)\n",
    "The code no longer crashes, but is the result correct? A key part of debugging is verifying the output. The formula for a simple geometric Brownian motion price update is $P_{t+1} = P_t \\cdot e^{(\\mu - \\frac{1}{2}\\sigma^2)\\Delta t + \\sigma \\sqrt{\\Delta t} Z_t}$, where $Z_t \\sim N(0,1)$. A simpler approximation is $P_{t+1} = P_t (1 + \\mu \\Delta t + \\sigma \\sqrt{\\Delta t} Z_t)$. Our current formula is `price_path[t] * (mu*dt + sigma*z*np.sqrt(dt))`, which is missing the `1 + ...` term, causing the price to plummet towards zero.\n",
    "\n",
    "- **Observation:** The prices are nonsensical, quickly becoming negative or near-zero. This is a \"silent bug\"—the code runs but produces the wrong answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Deeper Investigation (The Interactive Debugger)\n",
    "When a result is incorrect, we need to inspect the program's internal state. The best tool for this is an **interactive debugger**.\n",
    "\n",
    "- **Tool:** The `breakpoint()` function (Python 3.7+) drops you into a debugger session (`pdb`). For a better experience, install `ipdb` (`pip install ipdb`), and `breakpoint()` will use it automatically.\n",
    "- **Hypothesis 2:** The term `(mu*dt + sigma*z*np.sqrt(dt))` is a small number, and repeatedly multiplying by it drives the price down.\n",
    "- **Experiment:** Place `breakpoint()` inside the loop and inspect the variables.\n",
    "\n",
    "**Essential Debugger Commands:**\n",
    "- `p <expression>`: **Print** the value of an expression (e.g., `p price_path[t]`).\n",
    "- `n`: Execute the **next** line.\n",
    "- `s`: **Step** into a function call.\n",
    "- `c`: **Continue** execution until the next breakpoint or the end.\n",
    "- `l`: **List** source code around the current line.\n",
    "- `q`: **Quit** the debugger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the debugger, you would add `breakpoint()` to the code and run the cell. The execution will pause, and a `ipdb>` prompt will appear. You can then type commands to investigate. After confirming the formula is wrong, we can fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_asset_price_v3(p0, mu, sigma, T, dt, seed=None):\n",
    "    \"\"\"Version 3: Corrected the price update formula.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n_steps = int(T / dt)\n",
    "    price_path = np.zeros(n_steps)\n",
    "    price_path[0] = p0\n",
    "    \n",
    "    for t in range(n_steps - 1):\n",
    "        z = rng.standard_normal(1)\n",
    "        # Fix 2: Corrected the formula to include the '1 + ...' term.\n",
    "        price_path[t+1] = price_path[t] * (1 + mu*dt + sigma*z*np.sqrt(dt))\n",
    "        \n",
    "    return price_path\n",
    "\n",
    "sec(\"Experiment 2: Testing the Corrected Formula\")\n",
    "path_v3 = simulate_asset_price_v3(p0=100, mu=0.05, sigma=0.2, T=1, dt=0.01, seed=42)\n",
    "note(\"The path now looks much more reasonable.\")\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(path_v3)\n",
    "plt.title(\"Simulated Asset Price Path\")\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Proactive Debugging: Assertions and Logging\n",
    "After fixing the bugs, we should add defensive measures to catch future errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assertions for Invariants\n",
    "**Assertions** declare conditions (**invariants**) you believe must be true. If an assertion fails, it raises an `AssertionError`, stopping the program immediately. This is invaluable for catching bugs early and documenting your code's assumptions.\n",
    "\n",
    "> **When to Assert:** Use assertions to check for programmer errors (e.g., a volatility parameter that is negative) or to validate internal state. Use `try/except` blocks to handle expected runtime errors (e.g., a file not found)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logging for Diagnostics\n",
    "The `logging` module is the professional standard for diagnostics. It allows you to log messages at different severity levels (`DEBUG`, `INFO`, `WARNING`, `ERROR`), control verbosity, and direct output to files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_asset_price_final(p0, mu, sigma, T, dt, seed=None):\n",
    "    \"\"\"Final, robust version with assertions and logging.\"\"\"\n",
    "    logging.info(f\"Starting simulation with p0={p0}, mu={mu}, sigma={sigma}\")\n",
    "    \n",
    "    # Pre-condition assertions for valid economic parameters\n",
    "    assert p0 > 0, \"Initial price must be positive.\"\n",
    "    assert sigma >= 0, \"Volatility cannot be negative.\"\n",
    "    assert T > 0 and dt > 0, \"Time horizon and step must be positive.\"\n",
    "    \n",
    "    rng = np.random.default_rng(seed)\n",
    "    n_steps = int(T / dt)\n",
    "    price_path = np.zeros(n_steps + 1) # Correct size to hold n_steps + initial price\n",
    "    price_path[0] = p0\n",
    "    \n",
    "    for t in range(n_steps):\n",
    "        z = rng.standard_normal()\n",
    "        price_path[t+1] = price_path[t] * (1 + mu*dt + sigma*z*np.sqrt(dt))\n",
    "        # Post-condition: check for non-physical results like negative prices\n",
    "        if price_path[t+1] <= 0:\n",
    "            logging.warning(f\"Price became non-positive at step {t+1}. Clamping to zero.\")\n",
    "            price_path[t+1] = 0\n",
    "            break # Stop simulation if price hits zero\n",
    "            \n",
    "    logging.info(\"Simulation finished.\")\n",
    "    return price_path\n",
    "\n",
    "sec(\"Final Verification\")\n",
    "final_path = simulate_asset_price_final(p0=100, mu=0.05, sigma=0.2, T=5, dt=0.01, seed=42)\n",
    "note(\"Testing with invalid data (will raise AssertionError):\")\n",
    "try:\n",
    "    simulate_asset_price_final(p0=100, mu=0.05, sigma=-0.1, T=1, dt=0.1)\n",
    "except AssertionError as e:\n",
    "    print(f\"  Caught expected error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Profiling for Performance\n",
    "Once your code is correct, you may need to make it fast. **Profiling** is the process of measuring the execution time of different parts of your program to identify performance bottlenecks.\n",
    "\n",
    "> **Donald Knuth's Dictum**: \"Premature optimization is the root of all evil.\" Do not try to optimize code before you know it is correct and you have identified, through profiling, where the actual bottlenecks are.\n",
    "\n",
    "**Tools for Profiling in Jupyter:**\n",
    "- **`%timeit`**: A line magic for quickly measuring the execution time of a single statement.\n",
    "- **`%prun`**: A line magic that runs code with the standard Python profiler (`cProfile`) and shows a detailed report of function calls, execution times, and number of calls.\n",
    "- **`%lprun` (from `line_profiler`)**: A more granular profiler that measures the time spent on each individual line of code within a function. This is the best tool for pinpointing the exact line that is causing a bottleneck.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec(\"Profiling a Vectorized vs. Loop-based Simulation\")\n",
    "\n",
    "def simulate_vectorized(p0, mu, sigma, T, dt, n_paths, seed=None):\n",
    "    \"\"\"A fully vectorized simulation, no Python loops.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n_steps = int(T / dt)\n",
    "    # Generate all random shocks at once\n",
    "    z = rng.standard_normal((n_steps, n_paths))\n",
    "    # Calculate all returns at once\n",
    "    returns = 1 + mu*dt + sigma*z*np.sqrt(dt)\n",
    "    # Cumulatively multiply to get the path\n",
    "    price_paths = p0 * np.vstack([np.ones(n_paths), np.cumprod(returns, axis=0)])\n",
    "    return price_paths\n",
    "\n",
    "note(\"Profiling the vectorized implementation:\")\n",
    "%timeit simulate_vectorized(p0=100, mu=0.05, sigma=0.2, T=1, dt=0.01, n_paths=1000)\n",
    "\n",
    "note(\"\\nUsing %lprun to see the line-by-line cost:\")\n",
    "%lprun -f simulate_vectorized simulate_vectorized(p0=100, mu=0.05, sigma=0.2, T=1, dt=0.01, n_paths=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Exercises\n",
    "\n",
    "1.  **Read a Traceback:** Analyze the following code and the resulting traceback. What is the error type? On which line did it occur? What is the likely cause, and how would you fix it?\n",
    "    ```python\n",
    "    def calculate_portfolio_return(prices, weights):\n",
    "        # prices is a (T x N) matrix, weights is a (N,) vector\n",
    "        returns = prices.pct_change().dropna()\n",
    "        port_return = returns @ weights\n",
    "        return port_return\n",
    "    # Traceback: ...\n",
    "    # ValueError: shapes (99,5) and (99,5) not aligned: 5 (dim 1) != 99 (dim 0)\n",
    "    ```\n",
    "\n",
    "2.  **`ipdb` Practice:** Take the original `simulate_asset_price_buggy` function. Place a `breakpoint()` inside the loop. Call the function with `T=1, dt=0.5` (so `n_steps=2`). Use the debugger commands (`p t`, `p price_path`, `n`, `c`) to step through the function's two iterations and observe how the `price_path` array is updated, and confirm exactly when the `IndexError` occurs.\n",
    "\n",
    "3.  **Find the Bug:** The following function is supposed to solve a household's consumption-savings problem for two periods, but it contains a logical bug. The utility should be higher in the second scenario. Use debugging techniques to find and fix the bug.\n",
    "    ```python\n",
    "    def solve_c_s(y1, y2, r, beta):\n",
    "        # Solves for optimal c1, c2 given income y1, y2\n",
    "        # Utility is log(c1) + beta*log(c2)\n",
    "        # Bug is in this formula!\n",
    "        c1 = (y1 + y2/r) / (1 + beta)\n",
    "        c2 = (y1 + y2/r) * (1+r) / (1+beta) * beta\n",
    "        return np.log(c1) + beta * np.log(c2)\n",
    "\n",
    "    # Scenario 1: Smooth income\n",
    "    u1 = solve_c_s(y1=100, y2=100, r=0.05, beta=0.95)\n",
    "    # Scenario 2: Volatile income (but same total PV)\n",
    "    u2 = solve_c_s(y1=50, y2=155, r=0.05, beta=0.95)\n",
    "    print(f\"Utility 1: {u1:.2f}, Utility 2: {u2:.2f}\") # u2 should be higher!\n",
    "    ```\n",
    "\n",
    "4.  **Profiling:** Create two versions of a function that calculates the standard deviation of a large array: one that implements the formula $\\sigma = \\sqrt{\\frac{1}{N}\\sum_{i=1}^N (x_i - \\mu)^2}$ manually using Python loops, and one that just calls `np.std()`. Use `%timeit` to show that the NumPy version is orders of magnitude faster. Then use `%lprun` on your manual version to see how much time is spent on each line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Professional Code, Part II: Testing with Pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1 Why Test Economic Models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In computational economics, the correctness of our code is paramount. A small bug in an optimization routine, a misspecified boundary condition in a dynamic model, or a non-reproducible stochastic simulation can lead to incorrect economic conclusions, flawed policy recommendations, and non-replicable research. \n",
    "\n",
    "**Automated testing** is the practice of writing code that checks the correctness of other code. It provides a safety net that allows us to:\n",
    "- **Verify Correctness:** Ensure our algorithms are implemented correctly according to theory.\n",
    "- **Prevent Regressions:** Confidently refactor and improve code, knowing that our tests will catch any new bugs we might introduce.\n",
    "- **Improve Code Design:** Writing testable code often leads to better, more modular designs.\n",
    "- **Facilitate Collaboration and Replication:** Tests serve as a form of documentation and a guarantee to others that the code works as expected.\n",
    "\n",
    "For a PhD student, a robust test suite is a crucial component of a reproducible research compendium. It provides strong evidence that the computational results of a paper are reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2 The Testing Mindset: Arrange, Act, Assert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good test is simple, isolated, and follows the **Arrange-Act-Assert** pattern:\n",
    "\n",
    "1.  **Arrange:** Set up the necessary preconditions and inputs. This might involve creating mock data, defining model parameters, or instantiating an object.\n",
    "2.  **Act:** Execute the specific piece of code you want to test. This is typically a single function call or method invocation.\n",
    "3.  **Assert:** Check that the outcome of the action is what you expected. If the actual outcome does not match the expected outcome, the test fails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3 Introduction to `pytest`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pytest` is a mature, feature-rich, and easy-to-use testing framework for Python. It has become the de facto standard for Python testing due to its simple syntax and powerful features.\n",
    "\n",
    "##### Installation and Basic Usage\n",
    "\n",
    "Install `pytest` via pip:\n",
    "```bash\n",
    "pip install pytest\n",
    "```\n",
    "\n",
    "**Key Conventions:**\n",
    "- Test files should be named `test_*.py` or `*_test.py`.\n",
    "- Test functions inside these files must be named `test_*`.\n",
    "\n",
    "`pytest` will automatically discover and run these tests. To run your tests, simply navigate to your project's root directory in the terminal and run the command:\n",
    "```bash\n",
    "pytest\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.4 Practical Example 1: Testing a Simple Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "def production_function(K, L, alpha=0.33):\n",
    "    \"\"\"Calculates output using a Cobb-Douglas production function: Y = K^alpha * L^(1-alpha).\"\"\"\n",
    "    if K < 0 or L < 0:\n",
    "        raise ValueError(\"Capital and Labor inputs must be non-negative.\")\n",
    "    return (K**alpha) * (L**(1-alpha))\n",
    "\n",
    "def test_production_function_normal_inputs():\n",
    "    # Arrange\n",
    "    K, L, alpha = 100, 200, 0.33\n",
    "    expected_output = (100**alpha) * (200**(1-alpha))\n",
    "    # Act\n",
    "    actual_output = production_function(K, L, alpha)\n",
    "    # Assert\n",
    "    assert np.isclose(actual_output, expected_output)\n",
    "\n",
    "def test_production_function_zero_input():\n",
    "    # Arrange, Act, Assert\n",
    "    assert production_function(0, 100) == 0\n",
    "    assert production_function(100, 0) == 0\n",
    "\n",
    "def test_production_function_negative_input():\n",
    "    # Arrange, Act, Assert\n",
    "    with pytest.raises(ValueError):\n",
    "        production_function(-1, 100)\n",
    "    with pytest.raises(ValueError):\n",
    "        production_function(100, -1)\n",
    "\n",
    "# Simulate running the tests\n",
    "test_production_function_normal_inputs()\n",
    "test_production_function_zero_input()\n",
    "test_production_function_negative_input()\n",
    "print(\"Cobb-Douglas tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.5 Practical Example 2: Testing Numerical Accuracy in an Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_optimizer(objective_grad, initial_x, learning_rate=0.1, tol=1e-6, max_iter=1000):\n",
    "    \"\"\"A simple gradient descent optimizer.\"\"\"\n",
    "    x = initial_x\n",
    "    for _ in range(max_iter):\n",
    "        grad = objective_grad(x)\n",
    "        if abs(grad) < tol:\n",
    "            break\n",
    "        x = x - learning_rate * grad\n",
    "    return x\n",
    "\n",
    "def objective_grad(x):\n",
    "    \"\"\"Gradient of the function f(x) = (x-5)^2, which is 2*(x-5).\"\"\"\n",
    "    return 2 * (x - 5)\n",
    "\n",
    "def test_optimizer_finds_minimum():\n",
    "    # Arrange\n",
    "    initial_x = 0.0\n",
    "    known_minimum = 5.0\n",
    "    \n",
    "    # Act\n",
    "    found_minimum = simple_optimizer(objective_grad, initial_x)\n",
    "    \n",
    "    # Assert\n",
    "    # We use pytest.approx to handle floating point comparisons\n",
    "    assert found_minimum == pytest.approx(known_minimum, abs=1e-5)\n",
    "\n",
    "# Simulate running the test\n",
    "test_optimizer_finds_minimum()\n",
    "print(\"Optimizer test passed!\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
