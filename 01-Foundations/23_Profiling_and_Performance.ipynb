{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# === Environment Setup ===\n",
    "import os, sys, math, time, random, json, textwrap, warnings\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from numba import njit\n",
    "from IPython.display import display, Markdown\n",
    "# Load the line_profiler extension\n",
    "%load_ext line_profiler\n",
    "\n",
    "# --- Configuration ---\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams.update({'figure.dpi': 130, 'font.size': 12, 'axes.titlesize': 'x-large',\n",
    "    'axes.labelsize': 'large', 'xtick.labelsize': 'medium', 'ytick.labelsize': 'medium'})\n",
    "\n",
    "# --- Utility Functions ---\n",
    "def note(msg, **kwargs):\n",
    "    display(Markdown(f\"<div class='alert alert-info'>\ud83d\udcdd {textwrap.fill(msg, width=100)}</div>\"))\n",
    "def sec(title):\n",
    "    print(f\"\\n{100*'='}\\n| {title.upper()} |\\n{100*'='}\")\n",
    "\n",
    "note(\"Environment initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Foundations\n",
    "## Chapter 1.22: Profiling and Performance Optimization\n",
    "\n",
    "### Introduction: From Correctness to Speed\n",
    "\n",
    "Once your code is correct and well-tested, the next frontier is often performance. In computational economics, models can take hours or even days to run. The ability to identify and eliminate performance **bottlenecks** is a critical skill. **Profiling** is the systematic process of measuring the resource usage of your code—how much time it spends on each line or in each function—to find these bottlenecks.\n",
    "\n",
    "The cardinal rule of optimization, famously articulated by Donald Knuth, is: **\"Premature optimization is the root of all evil.\"** Do not attempt to optimize code before you have: \n",
    "1. Ensured it is correct (via tests).\n",
    "2. Profiled it to find the actual bottlenecks.\n",
    "\n",
    "This notebook introduces the essential profiling tools available in the Python ecosystem."
   ]
  },
    {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study: A Buffer-Stock Savings Model Simulation\n",
    "We will use a simple Monte Carlo simulation of a buffer-stock savings model as our test case. The model simulates the wealth of a household over time, which receives a stochastic income stream and saves to smooth consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_buffer_stock(n_sim=1000, T=500, r=0.01, sigma=0.1, rho=0.9, y_bar=1.0, c_bar=0.9):\n",
    "    \"\"\"Simulates wealth paths for a buffer-stock savings model.\"\"\"\n",
    "    wealth = np.zeros((T, n_sim))\n",
    "    log_y = np.zeros((T, n_sim))\n",
    "    \n",
    "    for t in range(T - 1):\n",
    "        log_y[t+1, :] = rho * log_y[t, :] + sigma * np.random.randn(n_sim)\n",
    "        y = y_bar * np.exp(log_y[t+1, :])\n",
    "        c = c_bar * wealth[t, :] + y\n",
    "        wealth[t+1, :] = (1 + r) * (wealth[t, :] - c) + y\n",
    "    return wealth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Quick Benchmarking with `%timeit`\n",
    "The IPython 'magic' command `%timeit` is the simplest tool for performance measurement. It repeatedly runs a single line of code to get a precise estimate of its average execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec(\"Benchmarking with %timeit\")\n",
    "%timeit simulate_buffer_stock()"
   ]
  },
    {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Function-Level Profiling with `cProfile`\n",
    "`%prun` (which uses the `cProfile` module) breaks down the total execution time by function. This is invaluable for identifying which functions are the most time-consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec(\"Function-Level Profiling with %prun\")\n",
    "%prun simulate_buffer_stock()"
   ]
  },
    {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Line-by-Line Profiling with `line_profiler`\n",
    "The most granular tool is `line_profiler`. It tells you exactly how much time was spent on *each line* of a function, allowing you to pinpoint the exact source of a bottleneck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec(\"Line-by-Line Profiling with %lprun\")\n",
    "# The -f flag specifies which function to profile\n",
    "%lprun -f simulate_buffer_stock simulate_buffer_stock()"
   ]
  },
    {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Optimization with Numba\n",
    "The profiling results clearly show that the bottleneck is the `for` loop. A common and powerful way to accelerate such loops in numerical Python is to use **Numba**, a just-in-time (JIT) compiler. By simply adding the `@njit` decorator, Numba will compile the function to highly efficient machine code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def simulate_buffer_stock_numba(n_sim=1000, T=500, r=0.01, sigma=0.1, rho=0.9, y_bar=1.0, c_bar=0.9):\n",
    "    \"\"\"Numba-optimized version of the simulation.\"\"\"\n",
    "    wealth = np.zeros((T, n_sim))\n",
    "    log_y = np.zeros((T, n_sim))\n",
    "    \n",
    "    for t in range(T - 1):\n",
    "        log_y[t+1, :] = rho * log_y[t, :] + sigma * np.random.randn(n_sim)\n",
    "        y = y_bar * np.exp(log_y[t+1, :])\n",
    "        c = c_bar * wealth[t, :] + y\n",
    "        wealth[t+1, :] = (1 + r) * (wealth[t, :] - c) + y\n",
    "    return wealth\n",
    "\n",
    "sec(\"Benchmarking the Numba-Optimized Version\")\n",
    "# Run once to compile\n",
    "_ = simulate_buffer_stock_numba()\n",
    "%timeit simulate_buffer_stock_numba()\n",
    "note(\"The Numba version is typically orders of magnitude faster, demonstrating the power of JIT compilation for numerical loops.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}