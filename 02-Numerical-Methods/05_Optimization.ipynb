{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# === Environment Setup ===\n",
    "import os, sys, math, time, random, json, textwrap, warnings\n",
    "from typing import Callable\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize, rosen, rosen_der, rosen_hess, linprog, basinhopping, differential_evolution\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# JAX for automatic differentiation\n",
    "try:\n",
    "    import jax\n",
    "    import jax.numpy as jnp\n",
    "    from jax import grad, hessian, jit\n",
    "    JAX_AVAILABLE = True\n",
    "except ImportError: JAX_AVAILABLE = False\n",
    "\n",
    "# CVXPY for disciplined convex programming\n",
    "try:\n",
    "    import cvxpy as cp\n",
    "    CVXPY_AVAILABLE = True\n",
    "except ImportError: CVXPY_AVAILABLE = False\n",
    "\n",
    "# --- Configuration ---\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams.update({'figure.dpi': 130, 'font.size': 12, 'axes.titlesize': 'x-large',\n",
    "    'axes.labelsize': 'large', 'xtick.labelsize': 'medium', 'ytick.labelsize': 'medium'})\n",
    "np.set_printoptions(suppress=True, linewidth=120, precision=4)\n",
    "\n",
    "# --- Utility Functions ---\n",
    "def note(msg, **kwargs):\n",
    "    display(Markdown(f\"<div class='alert alert-info'>üìù {textwrap.fill(msg, width=100)}</div>\"))\n",
    "def sec(title):\n",
    "    print(f\"\\n{100*'='}\\n| {title.upper()} |\\n{100*'='}\")\n",
    "\n",
    "note(f\"Environment initialized. JAX: {JAX_AVAILABLE}, CVXPY: {CVXPY_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Core Numerical Methods\n",
    "## Chapter 2.5: Optimization\n",
    "\n",
    "### Table of Contents\n",
    "1.  [The Landscape of Unconstrained Optimization](#1.-The-Landscape-of-Unconstrained-Optimization-Algorithms)\n",
    "    *   [1.1 First-Order vs. Second-Order vs. Derivative-Free Methods](#1.1-First-Order-vs.-Second-Order-vs.-Derivative-Free-Methods)\n",
    "    *   [1.2 Quasi-Newton Methods: The Workhorse (BFGS)](#1.2-Quasi-Newton-Methods:-The-Workhorse-(BFGS))\n",
    "2.  [Convex Optimization](#2.-Convex-Optimization)\n",
    "    *   [2.1 The Power of Convexity](#2.1-The-Power-of-Convexity)\n",
    "    *   [2.2 Disciplined Convex Programming with CVXPY](#2.2-Disciplined-Convex-Programming-with-CVXPY)\n",
    "3.  [Constrained Optimization](#3.-Constrained-Optimization)\n",
    "    *   [3.1 Geometric Interpretation of KKT Conditions](#3.1-Geometric-Interpretation-of-KKT-Conditions)\n",
    "    *   [3.2 Application: The Consumer's Problem](#3.2-Application:-The-Consumer's-Problem)\n",
    "4.  [Application: Mean-Variance Portfolio Optimization](#4.-Application:-Mean-Variance-Portfolio-Optimization)\n",
    "5.  [Global Optimization](#5.-Global-Optimization)\n",
    "    *   [5.1 Basinhopping](#5.1-Basinhopping)\n",
    "    *   [5.2 Differential Evolution](#5.2-Differential-Evolution)\n",
    "6.  [Chapter Summary](#6.-Chapter-Summary)\n",
    "7.  [Exercises](#7.-Exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction: The Heart of Economic Reasoning\n",
    "Optimization is the language of modern economics. The principle of constrained optimization is the foundation of our models of agent behavior: consumers maximize utility subject to a budget, firms maximize profits subject to a production technology, and social planners choose policies to maximize welfare. While analytical, \"pen-and-paper\" solutions are possible for simple, stylized models, most real-world problems in econometrics, structural estimation, and dynamic modeling are far too complex to be solved by hand. For these, we must rely on **numerical optimization**.\n",
    "\n",
    "This notebook provides a deep dive into the fundamental algorithms that power modern computational economics. We will explore the theory behind how optimizers work, apply professional-grade tools to solve economic models, and introduce the theory of constrained optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The Landscape of Unconstrained Optimization Algorithms\n",
    "For a smooth function $f: \\mathbb{R}^n \\to \\mathbb{R}$, we can use its derivatives to find a local minimum. The **Gradient**, $\\nabla f(x)$, is a vector of first partial derivatives that points in the direction of steepest local ascent. The **Hessian**, $\\nabla^2 f(x)$, is a matrix of second partial derivatives that describes the local curvature of the function.\n",
    "\n",
    "Most optimization algorithms are iterative. They start with an initial guess $\\mathbf{x}_0$ and generate a sequence $\\mathbf{x}_1, \\mathbf{x}_2, \\dots$ that converges to a solution $\\mathbf{x}^*$ where $\\nabla f(\\mathbf{x}^*) = 0$. The core of any algorithm is how it chooses the **search direction** ($\\mathbf{p}_k$) and the **step size** ($\\alpha_k$) to move from $\\mathbf{x}_k$ to the next point: $\\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha_k \\mathbf{p}_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 First-Order vs. Second-Order vs. Derivative-Free Methods\n",
    "- **First-Order (Gradient Descent):** Uses only the gradient $\\nabla f(x)$. Simple but can be slow.\n",
    "- **Second-Order (Newton's Method):** Uses both the gradient and the Hessian $\\nabla^2 f(x)$. Converges very fast but is computationally expensive.\n",
    "- **Derivative-Free (Nelder-Mead):** Uses only function values. Necessary for non-differentiable functions, but often slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Quasi-Newton Methods: The Workhorse (BFGS)\n",
    "Computing and inverting the Hessian is often computationally prohibitive. **Quasi-Newton methods** provide a powerful compromise. They avoid the explicit Hessian by instead building up an *approximation* to its inverse at each step, using only gradient information. The most popular of these methods is **BFGS** (Broyden‚ÄìFletcher‚ÄìGoldfarb‚ÄìShanno), which is the workhorse of unconstrained optimization and the default in many scientific libraries.",
    "\\nIntuitively, you can think of BFGS as a multi-dimensional generalization of the Secant method from root-finding. Just as the Secant method uses the slope between two points to approximate a derivative, BFGS uses the change in the gradient between two iterates to update its approximation of the inverse Hessian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Optimizer Paths on Rosenbrock Function](../images/02-Numerical-Methods/optimizer_paths.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Convex Optimization\n",
    "\n",
    "#### 2.1 The Power of Convexity\n",
    "A general non-linear optimization problem can be very hard to solve. The function may have many local minima, and algorithms can get stuck. **Convex optimization** is a special subfield that deals with minimizing a **convex function** over a **convex set**.\n",
    "\n",
    "A function $f$ is convex if the line segment between any two points on its graph lies on or above the graph. A set is convex if the line segment between any two points in the set is also in the set.\n",
    "\n",
    "The power of convexity comes from a simple, profound result: **for a convex optimization problem, any local minimum is also a global minimum.** This eliminates the central challenge of multi-modal functions and allows for the development of extremely efficient and reliable solvers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Disciplined Convex Programming with CVXPY\n",
    "**Disciplined Convex Programming (DCP)** is a framework for formally verifying that a problem is convex. The `CVXPY` library implements this framework, allowing users to express a problem in a natural, high-level syntax. `CVXPY` then automatically checks if the problem satisfies the DCP ruleset and, if so, converts it into a standard form that can be passed to highly-optimized convex solvers (like `ECOS` or `SCS`).\n",
    "\n",
    "This approach is more robust and often simpler than using a general-purpose non-linear solver for problems that can be formulated as convex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec(\"The Consumer Problem via Convex Optimization\")\n",
    "if not CVXPY_AVAILABLE:\n",
    "    note(\"CVXPY not installed. Skipping this section.\")\n",
    "else:\n",
    "    # 1. Define parameters and CVXPY variables\n",
    "    alpha, p1, p2, M = 0.5, 1, 2, 100\n",
    "    x1 = cp.Variable(pos=True) # pos=True is a constraint x1 >= 0\n",
    "    x2 = cp.Variable(pos=True)\n",
    "    \n",
    "    # 2. Define the convex objective and constraints\n",
    "    # To maximize log(u(x)), we maximize alpha*log(x1) + (1-alpha)*log(x2),\n",
    "    # which is a concave function (a convex minimization problem).\n",
    "    utility = alpha * cp.log(x1) + (1 - alpha) * cp.log(x2)\n",
    "    objective = cp.Maximize(utility)\n",
    "    constraints = [p1*x1 + p2*x2 <= M]\n",
    "    \n",
    "    # 3. Formulate and solve the problem\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve()\n",
    "    \n",
    "    note(f\"Problem status: {problem.status}\")\n",
    "    note(f\"Optimal consumption: x1={x1.value:.2f}, x2={x2.value:.2f}\")\n",
    "    note(f\"Max utility (log-utility): {problem.value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Advantage of Supplying Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For complex problems, providing the optimizer with analytically computed gradients and Hessians (e.g., via JAX) can lead to significant performance improvements and better accuracy compared to relying on finite-difference approximations. Let's demonstrate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\\n",
    "sec(\"Performance: Finite Differences vs. JAX Gradients\")\\n",
    "if JAX_AVAILABLE:\\n",
    "    # Define the Rosenbrock function in JAX\\n",
    "    def rosen_jax(x): return jnp.sum(100.0 * (x[1:] - x[:-1]**2.0)**2.0 + (1.0 - x[:-1])**2.0)\\n",
    "    # JIT-compile the function and its gradient\\n",
    "    rosen_jit = jit(rosen_jax)\\n",
    "    rosen_grad_jit = jit(grad(rosen_jax))\\n",
    "    x0_large = np.random.rand(100) * 2 - 1\\n",
    "    # Timing with finite-difference approximation\\n",
    "    time_no_grad = timeit.timeit(lambda: minimize(rosen, x0_large, method='BFGS'), number=10)\\n",
    "    # Timing with JAX-provided gradient\\n",
    "    time_with_grad = timeit.timeit(lambda: minimize(rosen_jit, x0_large, method='BFGS', jac=rosen_grad_jit), number=10)\\n",
    "    note(f'Time without JAX gradient: {time_no_grad:.4f}s\\nTime with JAX gradient: {time_with_grad:.4f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Constrained Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 The Importance of Constraints in Economics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearly every interesting economic problem is a constrained optimization problem. Agents maximize utility subject to a budget constraint. Firms maximize profits subject to a production technology. Planners maximize welfare subject to resource constraints.\n",
    "\n",
    "While we have studied the theoretical conditions for optimality (the Karush-Kuhn-Tucker conditions), we have not yet explored the practical algorithms used to solve these problems computationally. This notebook fills that gap by introducing two of the most powerful and widely used algorithms for non-linear constrained optimization: Sequential Quadratic Programming (SQP) and Interior-Point methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Karush-Kuhn-Tucker (KKT) Conditions Recap",
    "\\nThese conditions are named after Harold W. Kuhn and Albert W. Tucker, who formalized them in 1951, and William Karush, who had stated the conditions in his unpublished master's thesis in 1939. They generalize the method of Lagrange multipliers to include inequality constraints.\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the standard non-linear programming problem:\n",
    "$$ \\min_{x} f(x) \\quad \\text{s.t.} \\quad g_i(x) \\le 0, \\quad h_j(x) = 0 $$\n",
    "\n",
    "The KKT conditions are the necessary conditions for a solution to be optimal. They state that at an optimal point $x^*$, there must exist multipliers $\\mu_i^*$ and $\\lambda_j^*$ such that:\n",
    "1.  **Stationarity:** $\\nabla f(x^*) + \\sum_i \\mu_i^* \\nabla g_i(x^*) + \\sum_j \\lambda_j^* \\nabla h_j(x^*) = 0$\n",
    "2.  **Primal Feasibility:** $g_i(x^*) \\le 0$, $h_j(x^*) = 0$\n",
    "3.  **Dual Feasibility:** $\\mu_i^* \\ge 0$\n",
    "4.  **Complementary Slackness:** $\\mu_i^* g_i(x^*) = 0$\n",
    "\n",
    "Modern optimization algorithms can be thought of as sophisticated methods for finding a point $(x^*, \\mu^*, \\lambda^*)$ that satisfies this system of equations and inequalities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Algorithm 1: Sequential Quadratic Programming (SQP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQP is one of the most successful methods for non-linear constrained optimization. The core idea is to solve a sequence of simpler, quadratic programming (QP) subproblems that approximate the original problem.\n",
    "\n",
    "At each iteration $k$, the algorithm:\n",
    "1.  **Approximates the objective function** with a quadratic function around the current iterate $x_k$. This is done using a Taylor expansion of the Lagrangian function.\n",
    "2.  **Linearizes the constraints** around the current iterate $x_k$.\n",
    "3.  **Solves the resulting QP subproblem.** This QP is easier to solve than the original non-linear problem. The solution to the QP gives a search direction, $p_k$.\n",
    "4.  **Performs a line search** to find a step size $\\alpha_k$ that makes sufficient progress.\n",
    "5.  **Updates the iterate:** $x_{k+1} = x_k + \\alpha_k p_k$.\n",
    "\n",
    "This process is repeated until the KKT conditions are satisfied to a desired tolerance. SQP is particularly effective for problems with expensive function evaluations, as it can make rapid progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementation with `scipy.optimize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# --- Problem Setup ---\n",
    "alpha = 0.5\n",
    "px, py = 2, 5\n",
    "I = 100\n",
    "\n",
    "# Objective function (to be minimized)\n",
    "fun = lambda x: -( (x[0]**alpha) * (x[1]**(1-alpha)) )\n",
    "\n",
    "# Constraints\n",
    "constraints = ({'type': 'ineq', 'fun': lambda x: I - px*x[0] - py*x[1]})\n",
    "bounds = ((0, None), (0, None)) # x and y must be non-negative\n",
    "\n",
    "# Initial guess\n",
    "x0 = (10, 10)\n",
    "\n",
    "# --- Solve with SQP ---\n",
    "result_sqp = minimize(fun, x0, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "\n",
    "if result_sqp.success:\n",
    "    print(\"SQP Solution:\")\n",
    "    print(f\"  Optimal x: {result_sqp.x[0]:.2f}\")\n",
    "    print(f\"  Optimal y: {result_sqp.x[1]:.2f}\")\n",
    "    print(f\"  Max Utility: {-result_sqp.fun:.2f}\")\n",
    "else:\n",
    "    print(f\"SQP failed: {result_sqp.message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Algorithm 2: Interior-Point Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interior-Point methods take a different approach. They were originally developed for linear programming but have been extended to non-linear problems. The key idea is to handle inequality constraints by adding them to the objective function as a **barrier term**.\n",
    "\n",
    "For example, a constraint $g(x) \\le 0$ can be replaced by adding a term like $-\\mu \\log(-g(x))$ to the objective function. This barrier term is small when $x$ is far from the boundary ($g(x) \\ll 0$) but shoots to infinity as $x$ approaches the boundary ($g(x) \\to 0$).\n",
    "\n",
    "The algorithm then solves a sequence of unconstrained (or equality-constrained) problems with a decreasing barrier parameter $\\mu$. As $\\mu \\to 0$, the solution to the subproblem converges to the solution of the original constrained problem.\n",
    "\n",
    "These methods are called \"interior-point\" because they always maintain iterates that are strictly feasible with respect to the inequality constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementation with `scipy.optimize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Solve with Interior-Point (trust-constr) ---\n",
    "result_ip = minimize(fun, x0, method='trust-constr', bounds=bounds, constraints=constraints)\n",
    "\n",
    "if result_ip.success:\n",
    "    print(\"Interior-Point Solution:\")\n",
    "    print(f\"  Optimal x: {result_ip.x[0]:.2f}\")\n",
    "    print(f\"  Optimal y: {result_ip.x[1]:.2f}\")\n",
    "    print(f\"  Max Utility: {-result_ip.fun:.2f}\")\n",
    "else:\n",
    "    print(f\"Interior-Point failed: {result_ip.message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Comparison: SQP vs. Interior-Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both methods found the correct analytical solution, which is $x = \\frac{\\alpha I}{p_x} = 25$ and $y = \\frac{(1-\\alpha)I}{p_y} = 10$.\n",
    "\n",
    "So when should you choose one over the other?\n",
    "\n",
    "| Feature | Sequential Quadratic Programming (SQP) | Interior-Point Methods |\n",
    "|---|---|---|\n",
    "| **Best For** | Problems with expensive function/gradient evaluations. | Large-scale problems (many variables and constraints). |\n",
    "| **Feasibility** | Iterates are not necessarily feasible. | Iterates are always feasible w.r.t. inequality constraints. |\n",
    "| **Speed** | Can be very fast if good QP solver is available. | Often require more, but cheaper, iterations. |\n",
    "| **Robustness** | Can be sensitive to the initial guess. | Generally very robust. |\n",
    "\n",
    "For most problems encountered in economics, both are excellent choices. `scipy`'s `SLSQP` is often a great first choice due to its speed and versatility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Application: Mean-Variance Portfolio Optimization\n",
    "A cornerstone of modern finance is portfolio optimization. Given a set of assets with expected returns $\\boldsymbol{\\mu}$ and a covariance matrix $\\boldsymbol{\\Sigma}$, the classic Markowitz problem is to find the portfolio weights $\\mathbf{w}$ that minimize risk (variance, $\\mathbf{w}^T \\boldsymbol{\\Sigma} \\mathbf{w}$) for a given target level of expected return ($\"mu\"^T \\mathbf{w} \\ge R_0$). By solving this for a range of target returns, we can trace out the **efficient frontier**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Mean-Variance Efficient Frontier](../images/02-Numerical-Methods/efficient_frontier.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Global Optimization\n",
    "A critical weakness of the methods discussed so far is that they are **local optimizers**. They are only guaranteed to find a **local minimum**. If a function has multiple minima, the result will depend entirely on the starting point. Global optimization is a much harder problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Basinhopping\n",
    "`basinhopping` combines a local optimizer (like BFGS) with a random perturbation step, allowing it to \"hop\" between different basins of attraction in the function landscape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Differential Evolution\n",
    "**Differential Evolution** is a powerful, population-based global optimization algorithm. It maintains a population of candidate solutions and iteratively creates new candidates by combining existing ones. It is often very effective for difficult, non-convex, and non-differentiable problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec(\"Global Optimization with Differential Evolution\")\n",
    "# The Eggholder function is a very difficult test case with many local minima\n",
    "def eggholder(x):\n",
    "    return (-(x[1] + 47) * np.sin(np.sqrt(abs(x[0]/2 + (x[1]  + 47))))\n",
    "            -x[0] * np.sin(np.sqrt(abs(x[0] - (x[1]  + 47))))) \n",
    "\n",
    "bounds = [(-512, 512), (-512, 512)]\n",
    "result = differential_evolution(eggholder, bounds)\n",
    "note(f\"Global minimum found by Differential Evolution at x={result.x}, f(x)={result.fun:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Chapter Summary\n",
    "- **Know Your Algorithm:** Optimization involves a trade-off between speed and robustness. The choice of algorithm (gradient-based, Newton, derivative-free) depends on the problem structure.\n",
    "- **Convexity is a Superpower:** Convex problems are special because any local minimum is global. For such problems, specialized tools like `CVXPY` are more robust and reliable than general non-linear solvers.\n",
    "- **Constraints are Key:** The KKT conditions provide the theoretical foundation for constrained optimization, with a rich geometric interpretation.\n",
    "- **Local vs. Global:** Most standard optimizers are *local*. For functions with multiple minima, global optimization techniques like `basinhopping` or `differential_evolution` are necessary to avoid getting stuck in a suboptimal solution.\n",
    "- **Use the Right Tool:** Modern scientific computing relies on a combination of tools: `scipy.optimize` for general-purpose optimization, `JAX` for providing fast and accurate derivatives, and `CVXPY` for disciplined convex programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Exercises\n",
    "\n",
    "1.  **CVXPY for Cost Minimization:** A firm has a production function $Q = K^\\alpha L^{1-\\alpha}$. It wants to produce a target quantity $Q_0=100$ at minimum cost $C = rK + wL$. This is a convex optimization problem. Formulate and solve it using `CVXPY` for $\\alpha=0.5, r=1, w=2$. The dual variable (Lagrange multiplier) on the production constraint can be interpreted as the marginal cost. What is the marginal cost at the optimum?\n",
    "\n",
    "2.  **Portfolio with Short-Selling:** Modify the mean-variance portfolio optimization problem to allow for short-selling (i.e., remove the `bounds` that constrain weights to be positive). Re-calculate and plot the efficient frontier. How does it compare to the one with the no-short-selling constraint? Provide an intuition for the difference.\n",
    "\n",
    "3.  **Structural Estimation:** A researcher observes an agent making a consumption choice `c` when faced with income `M` and a wage `w`. The agent's utility is $U(c, l) = \\log(c) + \\theta \\log(l)$, where leisure is $l=1-h$ and hours worked are $h$. The budget constraint is $c = wh$. The researcher believes the agent is maximizing utility. \n",
    "    - **Task:** Write a function `solve_agent(theta, w)` that solves the agent's problem to find optimal consumption `c_star`. Then, write a function `objective(theta, observed_c, w)` that calculates the squared error `(c_star - observed_c)**2`. If the observed choice was `c=1.5` when `w=2`, use `scipy.optimize.minimize` to find the value of `theta` that makes your model's prediction match the observed data.\n",
    "\n",
    "4.  **Diet Problem (Linear Programming):** A student is trying to create the cheapest possible lunch that meets minimum nutritional requirements. The available foods are 'Pizza' and 'Salad'.\n",
    "    - Pizza: 500 calories, 10g protein, costs $3.\n",
    "    - Salad: 150 calories, 5g protein, costs $2.\n",
    "    The student needs at least 800 calories and 20g of protein. Formulate this as a linear programming problem and use `scipy.optimize.linprog` to find the optimal number of pizza slices and salad servings.\n\n",
    "5.  **Global Optimization:** The `six_hump_camel` function is a standard test function for global optimization. Find its documentation in `scipy.optimize` (or an equivalent library). Use `differential_evolution` to find its global minimum. How does the result compare to what you get from a standard local optimizer like `BFGS` starting from `x0 = (1, 1)`?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
