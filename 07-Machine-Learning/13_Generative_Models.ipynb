{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Environment Setup ===\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Markdown, Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# --- Configuration ---\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams.update({'font.size': 14, 'figure.figsize': (10, 6), 'figure.dpi': 150})\n",
    "np.set_printoptions(suppress=True, linewidth=120, precision=4)\n",
    "\n",
    "# --- Utility Functions ---\n",
    "def note(msg): display(Markdown(f\"<div class='alert alert-info'>üìù {msg}</div>\"))\n",
    "def sec(title): print(f'\\n{80*\"=\"}\\n| {title.upper()} |\\n{80*'='}\")\n",
    "\n",
    "note(\"Environment initialized for Generative Models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7.13: Generative Models\n",
    "\n",
    "---\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1.  [**Introduction to Generative Modeling**](#intro)\n",
    "2.  [**Variational Autoencoders (VAEs)**](#vae)\n",
    "    - [Architecture and Key Idea](#vae-arch)\n",
    "    - [The Reparameterization Trick](#reparam)\n",
    "    - [Code Lab: VAE for MNIST Generation](#code-vae)\n",
    "3.  [**Generative Adversarial Networks (GANs)**](#gan)\n",
    "    - [Architecture and Key Idea](#gan-arch)\n",
    "    - [The Adversarial Training Process](#gan-training)\n",
    "    - [Code Lab: Simple GAN for MNIST Generation](#code-gan)\n",
    "4.  [**A Brief History: Deep Belief Networks (DBNs)**](#dbn)\n",
    "5.  [**Summary**](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## 1. Introduction to Generative Modeling\n",
    "\n",
    "While **discriminative models** learn the boundary between classes (e.g., classifying an image as a cat or a dog), **generative models** learn the underlying distribution of the data itself. Their goal is to learn a model of $P(X)$ (the probability of the data) rather than $P(y|X)$ (the probability of a label given the data).\n",
    "\n",
    "This allows them to **generate new, synthetic data** that resembles the original data. This has profound applications, from creating artificial images and music to generating synthetic data for training other models, especially in situations where real-world data is scarce or private."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='vae'></a>\n",
    "## 2. Variational Autoencoders (VAEs)\n",
    "\n",
    "<a id='vae-arch'></a>\n",
    "### 2.1 Architecture and Key Idea\n",
    "\n",
    "A Variational Autoencoder (VAE) is a generative evolution of the standard autoencoder. Instead of learning a single, fixed encoding for each input, a VAE learns a **probability distribution** for the latent space.\n",
    "\n",
    "The encoder doesn't output a single vector; instead, it outputs two vectors: a vector of means ($\\mu$) and a vector of standard deviations ($\\sigma$). These parameters define a Gaussian distribution in the latent space. To generate a latent vector, we then **sample** from this distribution. This stochasticity is the key to the VAE's generative power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='../images/07-Machine-Learning/vae_architecture.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='reparam'></a>\n",
    "### 2.2 The Reparameterization Trick\n",
    "\n",
    "A challenge in training VAEs is that backpropagation cannot flow through a random sampling node. To solve this, VAEs use the **reparameterization trick**. Instead of sampling directly from $N(\\mu, \\sigma)$, we sample a random noise vector $\\epsilon$ from a standard normal distribution $N(0, 1)$ and then compute the latent vector $z$ as:\n",
    "$$ z = \\mu + \\sigma \\odot \\epsilon $$\n",
    "This way, the random part of the process is external to the network, and the gradients can flow back through the $\\mu$ and $\\sigma$ vectors to train the encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='code-vae'></a>\n",
    "### 2.3 Code Lab: VAE for MNIST Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec(\"Building and Training a VAE\")\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "latent_dim = 2\n",
    "\n",
    "# --- Encoder ---\n",
    "encoder_inputs = tf.keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "\n",
    "# --- Decoder ---\n",
    "latent_inputs = tf.keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((7, 7, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "\n",
    "# --- VAE Model ---\n",
    "class VAE(tf.keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.total_loss_tracker, self.reconstruction_loss_tracker, self.kl_loss_tracker]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(tf.reduce_sum(tf.keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)))\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\"loss\": self.total_loss_tracker.result(), \"reconstruction_loss\": self.reconstruction_loss_tracker.result(), \"kl_loss\": self.kl_loss_tracker.result()}\n",
    "\n",
    "# --- Load Data and Train ---\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
    "mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "note(\"Training VAE for 5 epochs as a demonstration. Full training would require more epochs.\")\n",
    "vae.fit(mnist_digits, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gan'></a>\n",
    "## 3. Generative Adversarial Networks (GANs)\n",
    "\n",
    "<a id='gan-arch'></a>\n",
    "### 3.1 Architecture and Key Idea\n",
    "\n",
    "Generative Adversarial Networks (GANs) are a powerful class of generative models introduced by Ian Goodfellow et al. in 2014. The core idea is an adversarial game between two neural networks:\n",
    "\n",
    "1.  **The Generator (G)**: This network takes random noise as input and tries to generate fake data that looks like the real data.\n",
    "2.  **The Discriminator (D)**: This network acts as a classifier. It is shown both real images (from the training set) and fake images (from the generator) and must learn to distinguish between them.\n",
    "\n",
    "The two networks are trained simultaneously in a zero-sum game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='../images/07-Machine-Learning/gan_architecture.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gan-training'></a>\n",
    "### 3.2 The Adversarial Training Process\n",
    "\n",
    "- The **Discriminator** is trained to maximize the probability of correctly classifying real and fake images. Its loss is high when it is fooled by the generator.\n",
    "- The **Generator** is trained to *minimize* the discriminator's ability to tell the difference. Its loss is high when the discriminator correctly identifies its output as fake.\n",
    "\n",
    "Over time, this adversarial process leads to a dynamic equilibrium where the generator produces increasingly realistic images to fool the ever-improving discriminator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='code-gan'></a>\n",
    "### 3.3 Code Lab: Simple GAN for MNIST Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec(\"Building and Training a Simple GAN\")\n",
    "\n",
    "# --- 1. Load and preprocess data ---\n",
    "(train_images, _), (_, _) = mnist.load_data()\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]\n",
    "BUFFER_SIZE = 60000; BATCH_SIZE = 256\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "# --- 2. Build the Generator ---\n",
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(7*7*256, use_bias=False, input_shape=(100,)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Reshape((7, 7, 256)),\n",
    "        layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# --- 3. Build the Discriminator ---\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# --- 4. Define Loss and Optimizers ---\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "# --- 5. Training Step ---\n",
    "generator = make_generator_model()\n",
    "discriminator = make_discriminator_model()\n",
    "\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, 100])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "# --- 6. Train the Model ---\n",
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for image_batch in dataset:\n",
    "            train_step(image_batch)\n",
    "        # Produce images for the GIF as we go\n",
    "        display.clear_output(wait=True)\n",
    "        note(f\"Epoch {epoch + 1} complete.\")\n",
    "\n",
    "note(\"Training GAN for 5 epochs as a demonstration. Full training is computationally intensive.\")\n",
    "train(train_dataset, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dbn'></a>\n",
    "## 4. A Brief History: Deep Belief Networks (DBNs)\n",
    "\n",
    "Before the rise of VAEs and GANs, **Deep Belief Networks (DBNs)** were a significant breakthrough in deep learning, pioneered by Geoffrey Hinton. DBNs are generative graphical models composed of multiple layers of latent variables ('hidden units'), where each layer is a **Restricted Boltzmann Machine (RBM)**.\n",
    "\n",
    "They are trained using a greedy, layer-by-layer unsupervised pre-training algorithm. While they have largely been superseded by VAEs and GANs for most generative tasks due to their computational expense and the difficulty of training, they were historically crucial for demonstrating that deep neural networks could be trained effectively, paving the way for the deep learning revolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='../images/07-Machine-Learning/dbn_architecture.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='summary'></a>\n",
    "## 5. Summary\n",
    "\n",
    "Generative models represent a major frontier in machine learning. VAEs and GANs are two of the most important architectures. VAEs learn a smooth, probabilistic latent space, making them excellent for tasks requiring a well-structured encoding. GANs, through their adversarial training, can often produce sharper, more realistic samples, but can be more unstable to train. Both have driven significant advances in AI's ability to create and understand complex data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}