{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Environment Setup ===\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Markdown, Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams.update({'font.size': 14, 'figure.figsize': (10, 6), 'figure.dpi': 150})\n",
    "np.set_printoptions(suppress=True, linewidth=120, precision=4)\n",
    "\n",
    "# --- Utility Functions ---\n",
    "def note(msg): display(Markdown(f\"<div class='alert alert-info'>üìù {msg}</div>\"))\n",
    "def sec(title): print(f'\\n{80*\"=\"}\\n| {title.upper()} |\\n{80*\"=\"}')\n",
    "\n",
    "note(\"Environment initialized for Autoencoders.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7.11: Autoencoders\n",
    "\n",
    "---\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1.  [**Introduction: Data Compression and Feature Learning**](#intro)\n",
    "2.  [**The Autoencoder Architecture**](#architecture)\n",
    "3.  [**Code Lab: Building a Simple Autoencoder for Denoising**](#code-lab)\n",
    "4.  [**Variational Autoencoders (VAEs)**](#vaes)\n",
    "5.  [**Summary**](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## 1. Introduction: Data Compression and Feature Learning\n",
    "\n",
    "An **autoencoder** is a type of neural network used for unsupervised learning. Its primary purpose is to learn a compressed, lower-dimensional representation (an **encoding**) of a dataset. The concept dates back to the 1980s and was explored by researchers like Geoffrey Hinton as a method for using neural networks to tackle high-dimensional data.\n",
    "\n",
    "Think of it like creating a summary of a book. To write a good summary, you must first understand the book's key themes, characters, and plot points. You compress the high-dimensional information of the full text into a low-dimensional summary. Then, someone else could read your summary and reconstruct a general, though not perfectly detailed, idea of the original book.\n",
    "\n",
    "Similarly, an autoencoder is trained to reconstruct its own input. This seemingly trivial task forces the network's internal layers to learn the most important, latent features of the data. By learning to ignore noise and capture only the essential patterns, it can effectively compress the data and then decompress it back into a form that closely resembles the original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='architecture'></a>\n",
    "## 2. The Autoencoder Architecture\n",
    "\n",
    "An autoencoder consists of two main parts:\n",
    "- **The Encoder:** This part of the network takes the input data and compresses it into a lower-dimensional latent space. This compressed vector is the \"encoding\" or the \"bottleneck.\"\n",
    "- **The Decoder:** This part of the network takes the compressed encoding and reconstructs the data back to its original dimensions.\n",
    "\n",
    "The network is trained by minimizing the **reconstruction loss**, which is a measure of the difference between the original input and the reconstructed output. The choice of loss function depends on the nature of the input data. For image data with pixel values between 0 and 1, **Binary Cross-Entropy** is often effective, treating each pixel as a Bernoulli distribution. For continuous data, **Mean Squared Error (MSE)** is a common choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Autoencoder Architecture](../images/07-Machine-Learning/autoencoder_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='code-lab'></a>\n",
    "## 3. Code Lab: Building a Simple Autoencoder for Denoising\n",
    "\n",
    "A powerful application of autoencoders is **denoising**. We can train an autoencoder to reconstruct clean images from noisy ones. This forces the model to learn the underlying structure of the data, ignoring the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec(\"Building and Training a Denoising Autoencoder\")\n",
    "\n",
    "# Load MNIST data\n",
    "(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
    "\n",
    "# Add random noise\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "\n",
    "# --- Model Architecture ---\n",
    "# We define a convolutional autoencoder. This is a good choice for image data\n",
    "# because convolutional layers are excellent at capturing spatial hierarchies.\n",
    "input_img = tf.keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "# The Encoder\n",
    "# We use a stack of Conv2D and MaxPooling2D layers to compress the image.\n",
    "# Each MaxPooling2D layer halves the spatial dimensions, forcing the network\n",
    "# to learn a more compressed representation.\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# The Decoder\n",
    "# The decoder mirrors the encoder's architecture, but in reverse.\n",
    "# We use UpSampling2D to increase the dimensions, aiming to reconstruct\n",
    "# the original image.\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = models.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "note(\"Training autoencoder for 10 epochs. This may take a few minutes.\")\n",
    "autoencoder.fit(x_train_noisy, x_train, epochs=10, batch_size=128, shuffle=True, validation_data=(x_test_noisy, x_test))\n",
    "\n",
    "note(\"Autoencoder training complete. Now, let's visualize the results.\")\n",
    "\n",
    "# --- Visualize Denoising ---\n",
    "decoded_imgs = autoencoder.predict(x_test_noisy)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='vaes'></a>\n",
    "## 4. Variational Autoencoders (VAEs)\n",
    "\n",
    "**Variational Autoencoders (VAEs)** are a more advanced, generative type of autoencoder. Instead of learning a single point encoding for each input, a VAE learns a **probability distribution** in the latent space. This allows us to sample from the latent space to generate new, synthetic data that resembles the original training data. VAEs are a key component of modern generative AI and are discussed in more detail in the **Chapter on Generative Models**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![VAE Architecture](../images/07-Machine-Learning/VAE_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='summary'></a>\n",
    "## 5. Summary\n",
    "\n",
    "Autoencoders are a versatile tool for unsupervised learning. They provide a powerful way to learn compressed representations of data, which can be used for dimensionality reduction, feature learning, and denoising. Their generative extension, the VAE, is a cornerstone of modern generative modeling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
