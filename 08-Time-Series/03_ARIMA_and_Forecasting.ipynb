{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Environment Setup ===\n",
    "!pip install prophet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "try:\n",
    "    import pandas_datareader.data as web\n",
    "    PDR_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PDR_AVAILABLE = False\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# --- Configuration ---\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams.update({'font.size': 14, 'figure.figsize': (12, 8), 'figure.dpi': 150})\n",
    "np.set_printoptions(suppress=True, linewidth=120, precision=4)\n",
    "\n",
    "# --- Utility Functions ---\n",
    "def note(msg): display(Markdown(f\"<div class='alert alert-info'>\ud83d\udcdd {msg}</div>\"))\n",
    "def sec(title): print(f'\\n{80*\"=\"}\\n| {title.upper()} |\\n{80*\"=\"}')\n",
    "\n",
    "note(\"Environment initialized for ARIMA and Forecasting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8.3: ARIMA Models and Forecasting\n",
    "\n",
    "---\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1.  [**Introduction: Handling Non-Stationary Time Series**](#intro)\n",
    "2.  [**Integrated Processes and Differencing**](#integrated)\n",
    "    - [The Random Walk: A Prototypical I(1) Process](#random-walk)\n",
    "3.  [**The ARIMA(p,d,q) Model**](#arima)\n",
    "4.  [**Forecasting with ARIMA**](#forecasting)\n",
    "    - [Case Study: Forecasting US Industrial Production](#case-study)\n",
    "5.  [**Model Validation and Evaluation**](#validation)\n",
    "    - [Time Series Cross-Validation](#cv)\n",
    "    - [Code Lab: Evaluating Forecast Accuracy](#code-cv)\n",
    "6.  [**Automated Forecasting with Prophet**](#prophet)\n",
    "7.  [**Exercises**](#exercises)\n",
    "8.  [**Summary and Key Takeaways**](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## 1. Introduction: Handling Non-Stationary Time Series\n",
    "\n",
    "The ARMA models introduced in the previous chapter are only suitable for **stationary** time series. However, most macroeconomic and financial time series are **non-stationary**; they exhibit clear trends or long-term movements that violate the stationarity conditions of constant mean and variance. The most common form of non-stationarity is a **unit root**, which gives rise to stochastic trends.\n",
    "\n",
    "This chapter introduces the **Autoregressive Integrated Moving Average (ARIMA)** model, which extends the ARMA framework to handle non-stationary data. The key innovation is the **\"Integrated\" (I)** component, which involves differencing the time series until it becomes stationary. Once the series is stationary, we can then model the differenced series with a standard ARMA model. This provides a powerful and flexible framework for modeling and forecasting a wide range of real-world economic time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='integrated'></a>\n",
    "## 2. Integrated Processes and Differencing\n",
    "\n",
    "A time series is said to be **integrated of order d**, denoted I(d), if it needs to be differenced $d$ times to become stationary. The most common case in economics is an I(1) process, which contains a unit root.\n",
    "\n",
    "<a id='random-walk'></a>\n",
    "### The Random Walk: A Prototypical I(1) Process\n",
    "The simplest I(1) process is the **random walk**:\n",
    "$$ y_t = y_{t-1} + \\epsilon_t $$\n",
    "Here, the value at time $t$ is simply the previous value plus a white noise shock. The mean of a random walk is constant (usually assumed to be zero), but its variance, $Var(y_t) = t \\sigma^2_\\epsilon$, grows over time, clearly violating the stationarity condition. Shocks to a random walk are **permanent**; they are fully incorporated into the level of the series forever.\n",
    "\n",
    "The solution is to take the **first difference** of the series:\n",
    "$$ \\Delta y_t = y_t - y_{t-1} = \\epsilon_t $$\n",
    "The differenced series, $\\Delta y_t$, is just a white noise process, which is stationary. Therefore, a random walk is an I(1) process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='arima'></a>\n",
    "## 3. The ARIMA(p,d,q) Model\n",
    "\n",
    "The ARIMA model combines the differencing step with an ARMA model. An **ARIMA(p,d,q)** model is specified by three orders:\n",
    "- **p**: The order of the autoregressive component.\n",
    "- **d**: The order of differencing.\n",
    "- **q**: The order of the moving average component.\n",
    "\n",
    "The modeling process is to first determine the order of integration, $d$, by repeatedly differencing the data and testing for stationarity (e.g., using an Augmented Dickey-Fuller test). Once a stationary series is obtained, we analyze its ACF and PACF plots to determine the appropriate AR and MA orders, $p$ and $q$, for an ARMA model on the differenced data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='forecasting'></a>\n",
    "## 4. Forecasting with ARIMA\n",
    "\n",
    "<a id='case-study'></a>\n",
    "### Case Study: Forecasting US Industrial Production\n",
    "We will now apply the full Box-Jenkins methodology to model and forecast the US Industrial Production Index (INDPRO) from the Federal Reserve Economic Data (FRED) database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec(\"Case Study: Forecasting US Industrial Production\")\n",
    "\n",
    "# 1. Load and plot the data\n",
    "if PDR_AVAILABLE:\n",
    "    note(\"Attempting to download monthly US Industrial Production data from FRED.\")\n",
    "    try:\n",
    "        start = '1980-01-01'\n",
    "        end = '2022-12-31'\n",
    "        indpro = web.DataReader('INDPRO', 'fred', start, end)\n",
    "        indpro.index.freq = 'MS'\n",
    "        log_indpro = np.log(indpro['INDPRO'])\n",
    "        note(\"Data downloaded successfully.\")\n",
    "    except Exception as e:\n",
    "        note(f\"Could not download data from FRED ({e}). Falling back to local CSV.\")\n",
    "        indpro = pd.read_csv('data/INDPRO.csv', index_col='observation_date', parse_dates=True)\n",
    "        indpro = indpro.loc['1980-01-01':'2022-12-31']\n",
    "        log_indpro = np.log(indpro['INDPRO'])\n",
    "else:\n",
    "    note(\"pandas_datareader not available. Loading data from local CSV.\")\n",
    "    indpro = pd.read_csv('data/INDPRO.csv', index_col='observation_date', parse_dates=True)\n",
    "    indpro = indpro.loc['1980-01-01':'2022-12-31']\n",
    "    log_indpro = np.log(indpro['INDPRO'])\n",
    "\n",
    "log_indpro.plot(title='Log US Industrial Production (1980-2022)')\n",
    "plt.show()\n",
    "note(\"The series clearly shows an upward trend, indicating it is non-stationary.\")\n",
    "\n",
    "# 2. Difference the data to achieve stationarity\n",
    "d_log_indpro = log_indpro.diff().dropna()\n",
    "d_log_indpro.plot(title='First Difference of Log Industrial Production')\n",
    "plt.show()\n",
    "note(\"The first difference appears stationary, suggesting d=1. We will now formally test this.\")\n",
    "\n",
    "    # 2a. Formal Test for Stationarity (Augmented Dickey-Fuller)\n",
    "    from statsmodels.tsa.stattools import adfuller\n",
    "    sec(\"Augmented Dickey-Fuller Test for Stationarity\")\n",
    "\n",
    "    # Test on the original (log-level) series\n",
    "    adf_test_level = adfuller(log_indpro)\n",
    "    print(f'ADF Statistic (Level): {adf_test_level[0]:.4f}')\n",
    "    print(f'p-value (Level): {adf_test_level[1]:.4f}')\n",
    "    note(f\"The p-value is high ({adf_test_level[1]:.4f}), so we fail to reject the null hypothesis of a unit root. The level series is non-stationary.\")\n",
    "\n",
    "    # Test on the differenced series\n",
    "    adf_test_diff = adfuller(d_log_indpro)\n",
    "    print(f'\\nADF Statistic (Difference): {adf_test_diff[0]:.4f}')\n",
    "    print(f'p-value (Difference): {adf_test_diff[1]:.4f}')\n",
    "    note(f\"The p-value is very low ({adf_test_diff[1]:.4f}), so we reject the null hypothesis. The differenced series is stationary.\")\n",
    "\n",
    "    # 3. Identify AR and MA orders using ACF/PACF\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    plot_acf(d_log_indpro, ax=ax1, lags=24)\n",
    "    plot_pacf(d_log_indpro, ax=ax2, lags=24)\n",
    "    plt.show()\n",
    "    note(\"The ACF and PACF plots both appear to tail off, suggesting a mixed ARMA model is appropriate.\")\n",
    "\n",
    "    # 4. Estimate the ARIMA model\n",
    "    note(\"Based on the plots, we will try an ARIMA(1,1,1) model.\")\n",
    "    model = ARIMA(log_indpro, order=(1, 1, 1))\n",
    "    results = model.fit()\n",
    "    print(results.summary())\n",
    "\n",
    "    # 5. Generate and plot forecasts\n",
    "    note(\"Generating out-of-sample forecasts for the next 24 months.\")\n",
    "    forecast_obj = results.get_forecast(steps=24)\n",
    "    forecast_ci = forecast_obj.conf_int()\n",
    "\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.plot(log_indpro, label='Observed')\n",
    "    plt.plot(forecast_obj.predicted_mean, label='Forecast', color='r')\n",
    "    plt.fill_between(forecast_ci.index, forecast_ci.iloc[:, 0], forecast_ci.iloc[:, 1], color='pink', alpha=0.5, label='95% Prediction Interval')\n",
    "    plt.title('Forecast of US Industrial Production')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='validation'></a>\n",
    "## 5. Model Validation and Evaluation\n",
    "\n",
    "While the Box-Jenkins/ARIMA methodology is a powerful classical approach, it's important to know how to properly validate its performance and to be aware of more modern, automated alternatives.\n",
    "\n",
    "<a id='cv'></a>\n",
    "### 5.1 Time Series Cross-Validation\n",
    "\n",
    "How can we rigorously evaluate a forecasting model's performance on unseen data? For non-temporal data, we often use k-fold cross-validation, which randomly splits the data into training and testing sets. This is **incorrect** for time series data, as it would involve training the model on future data to predict the past, leading to unrealistic performance metrics.\n",
    "\n",
    "The standard approach is **expanding window cross-validation** (or forward chaining). This procedure correctly mimics a real-world forecasting scenario:\n",
    "1. Start with an initial block of data for training.\n",
    "2. Make a forecast for the next period (the test set).\n",
    "3. 'Expand the window' by adding the test data to the training set.\n",
    "4. Repeat the process, always using the past to predict the future.\n",
    "\n",
    "Scikit-learn's `TimeSeriesSplit` implements this logic. The visualization below shows how each fold uses a progressively larger training set to forecast a subsequent, non-overlapping test set.\n",
    "\n",
    "![TimeSeriesSplit Visualization](images\png\timeseries_split_visualization.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='code-cv'></a>\n",
    "### 5.2 Code Lab: Evaluating Forecast Accuracy\n",
    "\n",
    "Let's use the expanding window approach to evaluate the 1-step-ahead forecast accuracy of our ARIMA(1,1,1) model for industrial production. We'll calculate the Root Mean Squared Error (RMSE) across all the test folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "sec(\"Evaluating ARIMA(1,1,1) with Time Series Cross-Validation\")\n",
    "\n",
    "X = log_indpro.values\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "errors = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    cv_train, cv_test = X[train_index], X[test_index]\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    model_cv = ARIMA(cv_train, order=(1, 1, 1))\n",
    "    results_cv = model_cv.fit()\n",
    "    \n",
    "    # Forecast the next step\n",
    "    forecast = results_cv.forecast(steps=len(cv_test))\n",
    "    \n",
    "    # Calculate the error\n",
    "    error = mean_squared_error(cv_test, forecast)\n",
    "    errors.append(error)\n",
    "\n",
    "rmse = np.sqrt(np.mean(errors))\n",
    "note(f\"The cross-validated Root Mean Squared Error (RMSE) for our ARIMA(1,1,1) model is: {rmse:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prophet'></a>\n",
    "## 6. Automated Forecasting with Prophet\n",
    "\n",
    "The Box-Jenkins methodology requires careful manual steps (differencing, interpreting ACF/PACF plots, checking residuals). In many business applications, a more automated and scalable approach is desired. Facebook's `Prophet` library was designed for this purpose.\n",
    "\n",
    "`Prophet` is a decomposable time series model that models a series $y(t)$ as a sum of several components:\n",
    "$$ y(t) = g(t) + s(t) + h(t) + \\epsilon_t $$\n",
    "- **$g(t)$ - Trend:** A piecewise linear or logistic growth curve. Prophet automatically detects changepoints in the trend.\n",
    "- **$s(t)$ - Seasonality:** A periodic component modeled with Fourier series (e.g., yearly, weekly, daily seasonality).\n",
    "- **$h(t)$ - Holidays:** A flexible component to model the effects of holidays and special events, which can be customized.\n",
    "- **$\\epsilon_t$ - Error:** A normally distributed error term.\n",
    "\n",
    "Its key advantage is that it provides a good, robust baseline forecast with sensible uncertainty intervals, often with very little manual effort. Let's apply it to our industrial production data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec(\"Forecasting with Prophet\")\n",
    "from prophet import Prophet\n",
    "\n",
    "# Prophet requires columns to be named 'ds' (datestamp) and 'y' (value)\n",
    "prophet_df = log_indpro.reset_index()\n",
    "prophet_df.columns = ['ds', 'y']\n",
    "\n",
    "# Instantiate and fit the model\n",
    "model_prophet = Prophet()\n",
    "model_prophet.fit(prophet_df)\n",
    "\n",
    "# Create a future dataframe to forecast into (24 months)\n",
    "future = model_prophet.make_future_dataframe(periods=24, freq='MS')\n",
    "forecast_prophet = model_prophet.predict(future)\n",
    "\n",
    "note(\"Prophet model fitted and forecast generated.\")\n",
    "fig = model_prophet.plot(forecast_prophet)\n",
    "plt.title('Prophet Forecast of US Industrial Production')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Log INDPRO')\n",
    "plt.show()\n",
    "\n",
    "note(\"Prophet automatically decomposes the time series into its components.\")\n",
    "fig2 = model_prophet.plot_components(forecast_prophet)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exercises'></a>\n",
    "## 7. Exercises\n",
    "\n",
    "1.  **Unit Root:** What is the root of the characteristic equation for a random walk process, $y_t = y_{t-1} + \\epsilon_t$? Where does this root lie with respect to the unit circle?\n",
    "2.  **Order of Integration:** If a time series $y_t$ has to be differenced twice to become stationary, what is its order of integration, and what would a plot of the series itself likely look like?\n",
    "3.  **Forecasting:** Look at the forecast plot for US Industrial Production. What happens to the point forecast over the long run? What happens to the width of the prediction interval? Explain why this is the case.\n",
    "4.  **Model Selection:** Using the `arma_order_select_ic` function from `statsmodels` (as shown in the previous notebook), find the best ARMA model for the differenced log industrial production series (`d_log_indpro`) according to the BIC. How does it compare to the ARIMA(1,1,1) model we chose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='summary'></a>\\n",
    "## 8. Summary and Key Takeaways\\n",
    "\\n",
    "This chapter extended the ARMA framework to non-stationary data using the ARIMA model, which is one of the most widely used tools for time series forecasting.\\n",
    "\\n",
    "**Key Concepts**:\\n",
    "- **Integrated Processes**: A series is integrated of order $d$, I(d), if it must be differenced $d$ times to become stationary. Most trending economic time series are I(1).\\n",
    "- **Differencing**: The key to handling unit root non-stationarity. First-differencing a series ($ \\Delta y_t = y_t - y_{t-1} $) models its changes, which are often stationary.\\n",
    "- **ARIMA(p,d,q) Models**: A composite model that first differences the data $d$ times, and then fits an ARMA(p,q) model to the resulting stationary series.\\n",
    "- **Forecasting**: Once an ARIMA model is estimated, it can be used to produce out-of-sample forecasts. The forecasts will eventually converge to the mean of the differenced series, and the uncertainty (width of the prediction intervals) will grow as the forecast horizon increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Solutions to Exercises\\n",
    "\\n",
    "---\\n",
    "\\n",
    "**1. Unit Root:**\\n",
    "The process is $y_t - y_{t-1} = \\epsilon_t$, which in lag operator notation is $(1-L)y_t = \\epsilon_t$. The characteristic equation is $1-z=0$. The root is $z=1$. This root lies *on* the unit circle, hence the name \"unit root process\".\\n",
    "\\n",
    "---\\n",
    "\\n",
    "**2. Order of Integration:**\\n",
    "It is integrated of order 2, or I(2). A plot of an I(2) series will typically show a more explosive, quadratic-like trend compared to the linear trend of an I(1) process.\\n",
    "\\n",
    "---\\n",
    "\\n",
    "**3. Forecasting:**\\n",
    "The point forecast for the log-level will converge to a straight line representing the long-run drift of the series. The prediction interval will continue to widen as the forecast horizon increases. This is because each step ahead adds more uncertainty. The variance of the forecast error for an $h$-step-ahead forecast is a function of $h$; as $h$ grows, so does the variance, reflecting that we are less certain about the distant future.\\n",
    "\\n",
    "---\\n",
    "\\n",
    "**4. Model Selection:**\\n",
    "You would run `arma_order_select_ic(d_log_indpro, max_ar=3, max_ma=3, ic='bic')`. The results would show a grid of BIC values for all ARMA(p,q) models up to (3,3). You would select the (p,q) combination with the lowest BIC value. This provides a more systematic approach to model selection than relying solely on visual inspection of the ACF/PACF plots."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}